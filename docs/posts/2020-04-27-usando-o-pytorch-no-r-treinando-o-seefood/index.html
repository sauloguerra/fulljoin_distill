<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

  <!--radix_placeholder_meta_tags-->
<title>Fulljoin: Usando o Pytorch no R: Treinando o Seefood</title>

<meta property="description" itemprop="description" content="Neste post iremos testar o uso do Pytorch no R com o auxílio do pacote reticulate, que permite a utilização de bibliotecas do Python diretamente no R. Isso ajuda a evitar (em parte) aquela disputa entre o R e o Python, uma vez que você pode usar o melhor de cada. Como exemplo, iremos treinar uma classificador de imagens que é a base do aplicativo Seefood que fez fama no seriado Silicon Valley da HBO."/>

<link rel="canonical" href="https://www.fulljoin.com.br/posts/2020-04-27-usando-o-pytorch-no-r-treinando-o-seefood/"/>

<!--  https://schema.org/Article -->
<meta property="article:published" itemprop="datePublished" content="2020-04-27"/>
<meta property="article:created" itemprop="dateCreated" content="2020-04-27"/>
<meta name="article:author" content="Paulo Felipe Alencar"/>

<!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
<meta property="og:title" content="Fulljoin: Usando o Pytorch no R: Treinando o Seefood"/>
<meta property="og:type" content="article"/>
<meta property="og:description" content="Neste post iremos testar o uso do Pytorch no R com o auxílio do pacote reticulate, que permite a utilização de bibliotecas do Python diretamente no R. Isso ajuda a evitar (em parte) aquela disputa entre o R e o Python, uma vez que você pode usar o melhor de cada. Como exemplo, iremos treinar uma classificador de imagens que é a base do aplicativo Seefood que fez fama no seriado Silicon Valley da HBO."/>
<meta property="og:url" content="https://www.fulljoin.com.br/posts/2020-04-27-usando-o-pytorch-no-r-treinando-o-seefood/"/>
<meta property="og:image" content="https://www.fulljoin.com.br/posts/2020-04-27-usando-o-pytorch-no-r-treinando-o-seefood/usando-o-pytorch-no-r-treinando-o-seefood_files/figure-html5/unnamed-chunk-5-1.png"/>
<meta property="og:image:width" content="1248"/>
<meta property="og:image:height" content="1344"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:site_name" content="Fulljoin"/>

<!--  https://dev.twitter.com/cards/types/summary -->
<meta property="twitter:card" content="summary_large_image"/>
<meta property="twitter:title" content="Fulljoin: Usando o Pytorch no R: Treinando o Seefood"/>
<meta property="twitter:description" content="Neste post iremos testar o uso do Pytorch no R com o auxílio do pacote reticulate, que permite a utilização de bibliotecas do Python diretamente no R. Isso ajuda a evitar (em parte) aquela disputa entre o R e o Python, uma vez que você pode usar o melhor de cada. Como exemplo, iremos treinar uma classificador de imagens que é a base do aplicativo Seefood que fez fama no seriado Silicon Valley da HBO."/>
<meta property="twitter:url" content="https://www.fulljoin.com.br/posts/2020-04-27-usando-o-pytorch-no-r-treinando-o-seefood/"/>
<meta property="twitter:image" content="https://www.fulljoin.com.br/posts/2020-04-27-usando-o-pytorch-no-r-treinando-o-seefood/usando-o-pytorch-no-r-treinando-o-seefood_files/figure-html5/unnamed-chunk-5-1.png"/>
<meta property="twitter:image:width" content="1248"/>
<meta property="twitter:image:height" content="1344"/>

<!--  https://scholar.google.com/intl/en/scholar/inclusion.html#indexing -->
<meta name="citation_title" content="Fulljoin: Usando o Pytorch no R: Treinando o Seefood"/>
<meta name="citation_fulltext_html_url" content="https://www.fulljoin.com.br/posts/2020-04-27-usando-o-pytorch-no-r-treinando-o-seefood/"/>
<meta name="citation_online_date" content="2020/04/27"/>
<meta name="citation_publication_date" content="2020/04/27"/>
<meta name="citation_author" content="Paulo Felipe Alencar"/>
<!--/radix_placeholder_meta_tags-->
  <!--radix_placeholder_rmarkdown_metadata-->

<script type="text/json" id="radix-rmarkdown-metadata">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","date","output","draft","citation_url","canonical_url"]}},"value":[{"type":"character","attributes":{},"value":["Usando o Pytorch no R: Treinando o Seefood"]},{"type":"character","attributes":{},"value":["Neste post iremos testar o uso do Pytorch no R com o auxílio do pacote reticulate, que permite a utilização de bibliotecas do Python diretamente no R. Isso ajuda a evitar (em parte) aquela disputa entre o R e o Python, uma vez que você pode usar o melhor de cada. Como exemplo, iremos treinar uma classificador de imagens que é a base do aplicativo Seefood que fez fama no seriado Silicon Valley da HBO."]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name"]}},"value":[{"type":"character","attributes":{},"value":["Paulo Felipe Alencar"]}]}]},{"type":"character","attributes":{},"value":["04-27-2020"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained"]}},"value":[{"type":"logical","attributes":{},"value":[false]}]}]},{"type":"logical","attributes":{},"value":[false]},{"type":"character","attributes":{},"value":["https://www.fulljoin.com.br/posts/2020-04-27-usando-o-pytorch-no-r-treinando-o-seefood/"]},{"type":"character","attributes":{},"value":["https://www.fulljoin.com.br/posts/2020-04-27-usando-o-pytorch-no-r-treinando-o-seefood/"]}]}
</script>
<!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["usando-o-pytorch-no-r-treinando-o-seefood_files/bowser-1.9.3/bowser.min.js","usando-o-pytorch-no-r-treinando-o-seefood_files/distill-2.2.21/template.v2.js","usando-o-pytorch-no-r-treinando-o-seefood_files/figure-html5/unnamed-chunk-3-1.png","usando-o-pytorch-no-r-treinando-o-seefood_files/figure-html5/unnamed-chunk-5-1.png","usando-o-pytorch-no-r-treinando-o-seefood_files/figure-html5/unnamed-chunk-8-1.png","usando-o-pytorch-no-r-treinando-o-seefood_files/jquery-1.11.3/jquery.min.js","usando-o-pytorch-no-r-treinando-o-seefood_files/webcomponents-2.0.0/webcomponents.js"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->

<script type="application/javascript">

  window.headroom_prevent_pin = false;

  window.document.addEventListener("DOMContentLoaded", function (event) {

    // initialize headroom for banner
    var header = $('header').get(0);
    var headerHeight = header.offsetHeight;
    var headroom = new Headroom(header, {
      onPin : function() {
        if (window.headroom_prevent_pin) {
          window.headroom_prevent_pin = false;
          headroom.unpin();
        }
      }
    });
    headroom.init();
    if(window.location.hash)
      headroom.unpin();
    $(header).addClass('headroom--transition');

    // offset scroll location for banner on hash change
    // (see: https://github.com/WickyNilliams/headroom.js/issues/38)
    window.addEventListener("hashchange", function(event) {
      window.scrollTo(0, window.pageYOffset - (headerHeight + 25));
    });

    // responsive menu
    $('.distill-site-header').each(function(i, val) {
      var topnav = $(this);
      var toggle = topnav.find('.nav-toggle');
      toggle.on('click', function() {
        topnav.toggleClass('responsive');
      });
    });

    // nav dropdowns
    $('.nav-dropbtn').click(function(e) {
      $(this).next('.nav-dropdown-content').toggleClass('nav-dropdown-active');
      $(this).parent().siblings('.nav-dropdown')
         .children('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $("body").click(function(e){
      $('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $(".nav-dropdown").click(function(e){
      e.stopPropagation();
    });
  });
</script>

<style type="text/css">

/* Theme (user-documented overrideables for nav appearance) */

.distill-site-nav {
  color: rgba(255, 255, 255, 0.8);
  background-color: #455a64;
  font-size: 15px;
  font-weight: 300;
}

.distill-site-nav a {
  color: inherit;
  text-decoration: none;
}

.distill-site-nav a:hover {
  color: white;
}

@media print {
  .distill-site-nav {
    display: none;
  }
}

.distill-site-header {

}

.distill-site-footer {

}


/* Site Header */

.distill-site-header {
  width: 100%;
  box-sizing: border-box;
  z-index: 3;
}

.distill-site-header .nav-left {
  display: inline-block;
  margin-left: 8px;
}

@media screen and (max-width: 768px) {
  .distill-site-header .nav-left {
    margin-left: 0;
  }
}


.distill-site-header .nav-right {
  float: right;
  margin-right: 8px;
}

.distill-site-header a,
.distill-site-header .title {
  display: inline-block;
  text-align: center;
  padding: 14px 10px 14px 10px;
}

.distill-site-header .title {
  font-size: 18px;
}

.distill-site-header .logo {
  padding: 0;
}

.distill-site-header .logo img {
  display: none;
  max-height: 20px;
  width: auto;
  margin-bottom: -4px;
}

.distill-site-header .nav-image img {
  max-height: 18px;
  width: auto;
  display: inline-block;
  margin-bottom: -3px;
}



@media screen and (min-width: 1000px) {
  .distill-site-header .logo img {
    display: inline-block;
  }
  .distill-site-header .nav-left {
    margin-left: 20px;
  }
  .distill-site-header .nav-right {
    margin-right: 20px;
  }
  .distill-site-header .title {
    padding-left: 12px;
  }
}


.distill-site-header .nav-toggle {
  display: none;
}

.nav-dropdown {
  display: inline-block;
  position: relative;
}

.nav-dropdown .nav-dropbtn {
  border: none;
  outline: none;
  color: rgba(255, 255, 255, 0.8);
  padding: 16px 10px;
  background-color: transparent;
  font-family: inherit;
  font-size: inherit;
  font-weight: inherit;
  margin: 0;
  margin-top: 1px;
  z-index: 2;
}

.nav-dropdown-content {
  display: none;
  position: absolute;
  background-color: white;
  min-width: 200px;
  border: 1px solid rgba(0,0,0,0.15);
  border-radius: 4px;
  box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.1);
  z-index: 1;
  margin-top: 2px;
  white-space: nowrap;
  padding-top: 4px;
  padding-bottom: 4px;
}

.nav-dropdown-content hr {
  margin-top: 4px;
  margin-bottom: 4px;
  border: none;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.nav-dropdown-active {
  display: block;
}

.nav-dropdown-content a, .nav-dropdown-content .nav-dropdown-header {
  color: black;
  padding: 6px 24px;
  text-decoration: none;
  display: block;
  text-align: left;
}

.nav-dropdown-content .nav-dropdown-header {
  display: block;
  padding: 5px 24px;
  padding-bottom: 0;
  text-transform: uppercase;
  font-size: 14px;
  color: #999999;
  white-space: nowrap;
}

.nav-dropdown:hover .nav-dropbtn {
  color: white;
}

.nav-dropdown-content a:hover {
  background-color: #ddd;
  color: black;
}

.nav-right .nav-dropdown-content {
  margin-left: -45%;
  right: 0;
}

@media screen and (max-width: 768px) {
  .distill-site-header a, .distill-site-header .nav-dropdown  {display: none;}
  .distill-site-header a.nav-toggle {
    float: right;
    display: block;
  }
  .distill-site-header .title {
    margin-left: 0;
  }
  .distill-site-header .nav-right {
    margin-right: 0;
  }
  .distill-site-header {
    overflow: hidden;
  }
  .nav-right .nav-dropdown-content {
    margin-left: 0;
  }
}


@media screen and (max-width: 768px) {
  .distill-site-header.responsive {position: relative;}
  .distill-site-header.responsive a.nav-toggle {
    position: absolute;
    right: 0;
    top: 0;
  }
  .distill-site-header.responsive a,
  .distill-site-header.responsive .nav-dropdown {
    display: block;
    text-align: left;
  }
  .distill-site-header.responsive .nav-left,
  .distill-site-header.responsive .nav-right {
    width: 100%;
  }
  .distill-site-header.responsive .nav-dropdown {float: none;}
  .distill-site-header.responsive .nav-dropdown-content {position: relative;}
  .distill-site-header.responsive .nav-dropdown .nav-dropbtn {
    display: block;
    width: 100%;
    text-align: left;
  }
}

/* Site Footer */

.distill-site-footer {
  width: 100%;
  overflow: hidden;
  box-sizing: border-box;
  z-index: 3;
  margin-top: 30px;
  padding-top: 30px;
  padding-bottom: 30px;
  text-align: center;
}

/* Headroom */

d-title {
  padding-top: 6rem;
}

@media print {
  d-title {
    padding-top: 4rem;
  }
}

.headroom {
  z-index: 1000;
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
}

.headroom--transition {
  transition: all .4s ease-in-out;
}

.headroom--unpinned {
  top: -100px;
}

.headroom--pinned {
  top: 0;
}

</style>

<link href="../../site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet"/>
<link href="../../site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet"/>
<script src="../../site_libs/headroom-0.9.4/headroom.min.js"></script>
<!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

<style type="text/css">

body {
  background-color: white;
}

.pandoc-table {
  width: 100%;
}

.pandoc-table>caption {
  margin-bottom: 10px;
}

.pandoc-table th:not([align]) {
  text-align: left;
}

.pagedtable-footer {
  font-size: 15px;
}

.html-widget {
  margin-bottom: 2.0em;
}

.l-screen-inset {
  padding-right: 16px;
}

.l-screen .caption {
  margin-left: 10px;
}

.shaded {
  background: rgb(247, 247, 247);
  padding-top: 20px;
  padding-bottom: 20px;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .html-widget {
  margin-bottom: 0;
  border: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .shaded-content {
  background: white;
}

.text-output {
  margin-top: 0;
  line-height: 1.5em;
}

.hidden {
  display: none !important;
}

d-article {
  padding-bottom: 30px;
}

d-appendix {
  padding-top: 30px;
}

d-article>p>img {
  width: 100%;
}

d-article iframe {
  border: 1px solid rgba(0, 0, 0, 0.1);
  margin-bottom: 2.0em;
  width: 100%;
}

figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

/* CSS for table of contents */

.d-toc {
  color: rgba(0,0,0,0.8);
  font-size: 0.8em;
  line-height: 1em;
}

.d-toc-header {
  font-size: 0.6rem;
  font-weight: 400;
  color: rgba(0, 0, 0, 0.5);
  text-transform: uppercase;
  margin-top: 0;
  margin-bottom: 1.3em;
}

.d-toc a {
  border-bottom: none;
}

.d-toc ul {
  padding-left: 0;
}

.d-toc li>ul {
  padding-top: 0.8em;
  padding-left: 16px;
  margin-bottom: 0.6em;
}

.d-toc ul,
.d-toc li {
  list-style-type: none;
}

.d-toc li {
  margin-bottom: 0.9em;
}

.d-toc-separator {
  margin-top: 20px;
  margin-bottom: 2em;
}

.d-article-with-toc {
  border-top: none;
  padding-top: 0;
}



/* Tweak code blocks (note that this CSS is repeated above in an injection
   into the d-code shadow dom) */

d-code {
  overflow-x: auto !important;
}

pre.d-code code.d-code {
  padding-left: 10px;
  font-size: 12px;
  border-left: 2px solid rgba(0,0,0,0.1);
}

pre.text-output {

  font-size: 12px;
  color: black;
  background: none;
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

@media(min-width: 768px) {

d-code {
  overflow-x: visible !important;
}

pre.d-code code.d-code  {
    padding-left: 18px;
    font-size: 14px;
}
pre.text-output {
  font-size: 14px;
}
}

/* Figure */

.figure {
  position: relative;
  margin-bottom: 2.5em;
  margin-top: 1.5em;
}

.figure img {
  width: 100%;
}

.figure .caption {
  color: rgba(0, 0, 0, 0.6);
  font-size: 12px;
  line-height: 1.5em;
}

.figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

.figure .caption a {
  color: rgba(0, 0, 0, 0.6);
}

.figure .caption b,
.figure .caption strong, {
  font-weight: 600;
  color: rgba(0, 0, 0, 1.0);
}



/* Tweak 1000px media break to show more text */

@media(min-width: 1000px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 16px;
  }

  .grid {
    grid-column-gap: 16px;
  }

  d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
  }
  figure .caption, .figure .caption, figure figcaption {
    font-size: 13px;
  }
}

@media(min-width: 1180px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 32px;
  }

  .grid {
    grid-column-gap: 32px;
  }
}


/* Get the citation styles for the appendix (not auto-injected on render since
   we do our own rendering of the citation appendix) */

d-appendix .citation-appendix,
.d-appendix .citation-appendix {
  font-size: 11px;
  line-height: 15px;
  border-left: 1px solid rgba(0, 0, 0, 0.1);
  padding-left: 18px;
  border: 1px solid rgba(0,0,0,0.1);
  background: rgba(0, 0, 0, 0.02);
  padding: 10px 18px;
  border-radius: 3px;
  color: rgba(150, 150, 150, 1);
  overflow: hidden;
  margin-top: -12px;
  white-space: pre-wrap;
  word-wrap: break-word;
}


/* Social footer */

.social_footer {
  margin-top: 30px;
  margin-bottom: 0;
  color: rgba(0,0,0,0.67);
}

.disqus-comments {
  margin-right: 30px;
}

.disqus-comment-count {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  cursor: pointer;
}

#disqus_thread {
  margin-top: 30px;
}

.article-sharing a {
  border-bottom: none;
  margin-right: 8px;
}

.article-sharing a:hover {
  border-bottom: none;
}

.sidebar-section.subscribe {
  font-size: 12px;
  line-height: 1.6em;
}

.subscribe p {
  margin-bottom: 0.5em;
}


.article-footer .subscribe {
  font-size: 15px;
  margin-top: 45px;
}


/* Improve display for browsers without grid (IE/Edge <= 15) */

.downlevel {
  line-height: 1.6em;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  margin: 0;
}

.downlevel .d-title {
  padding-top: 6rem;
  padding-bottom: 1.5rem;
}

.downlevel .d-title h1 {
  font-size: 50px;
  font-weight: 700;
  line-height: 1.1em;
  margin: 0 0 0.5rem;
}

.downlevel .d-title p {
  font-weight: 300;
  font-size: 1.2rem;
  line-height: 1.55em;
  margin-top: 0;
}

.downlevel .d-byline {
  padding-top: 0.8em;
  padding-bottom: 0.8em;
  font-size: 0.8rem;
  line-height: 1.8em;
}

.downlevel .section-separator {
  border: none;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
}

.downlevel .d-article {
  font-size: 1.06rem;
  line-height: 1.7em;
  padding-top: 1rem;
  padding-bottom: 2rem;
}


.downlevel .d-appendix {
  padding-left: 0;
  padding-right: 0;
  max-width: none;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.5);
  padding-top: 40px;
  padding-bottom: 48px;
}

.downlevel .footnotes ol {
  padding-left: 13px;
}

.downlevel .base-grid,
.downlevel .distill-header,
.downlevel .d-title,
.downlevel .d-abstract,
.downlevel .d-article,
.downlevel .d-appendix,
.downlevel .distill-appendix,
.downlevel .d-byline,
.downlevel .d-footnote-list,
.downlevel .d-citation-list,
.downlevel .distill-footer,
.downlevel .appendix-bottom,
.downlevel .posts-container {
  padding-left: 40px;
  padding-right: 40px;
}

@media(min-width: 768px) {
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
  padding-left: 150px;
  padding-right: 150px;
  max-width: 900px;
}
}

.downlevel pre code {
  display: block;
  border-left: 2px solid rgba(0, 0, 0, .1);
  padding: 0 0 0 20px;
  font-size: 14px;
}

.downlevel code, .downlevel pre {
  color: black;
  background: none;
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

</style>

<script type="application/javascript">

function is_downlevel_browser() {
  if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                 window.navigator.userAgent)) {
    return true;
  } else {
    return window.load_distill_framework === undefined;
  }
}

// show body when load is complete
function on_load_complete() {

  // set body to visible
  document.body.style.visibility = 'visible';

  // force redraw for leaflet widgets
  if (window.HTMLWidgets) {
    var maps = window.HTMLWidgets.findAll(".leaflet");
    $.each(maps, function(i, el) {
      var map = this.getMap();
      map.invalidateSize();
      map.eachLayer(function(layer) {
        if (layer instanceof L.TileLayer)
          layer.redraw();
      });
    });
  }

  // trigger 'shown' so htmlwidgets resize
  $('d-article').trigger('shown');
}

function init_distill() {

  init_common();

  // create front matter
  var front_matter = $('<d-front-matter></d-front-matter>');
  $('#distill-front-matter').wrap(front_matter);

  // create d-title
  $('.d-title').changeElementType('d-title');

  // create d-byline
  var byline = $('<d-byline></d-byline>');
  $('.d-byline').replaceWith(byline);

  // create d-article
  var article = $('<d-article></d-article>');
  $('.d-article').wrap(article).children().unwrap();

  // move posts container into article
  $('.posts-container').appendTo($('d-article'));

  // create d-appendix
  $('.d-appendix').changeElementType('d-appendix');

  // create d-bibliography
  var bibliography = $('<d-bibliography></d-bibliography>');
  $('#distill-bibliography').wrap(bibliography);

  // flag indicating that we have appendix items
  var appendix = $('.appendix-bottom').children('h3').length > 0;

  // replace citations with <d-cite>
  $('.citation').each(function(i, val) {
    appendix = true;
    var cites = $(this).attr('data-cites').split(" ");
    var dt_cite = $('<d-cite></d-cite>');
    dt_cite.attr('key', cites.join());
    $(this).replaceWith(dt_cite);
  });
  // remove refs
  $('#refs').remove();

  // replace footnotes with <d-footnote>
  $('.footnote-ref').each(function(i, val) {
    appendix = true;
    var href = $(this).attr('href');
    var id = href.replace('#', '');
    var fn = $('#' + id);
    var fn_p = $('#' + id + '>p');
    fn_p.find('.footnote-back').remove();
    var text = fn_p.html();
    var dtfn = $('<d-footnote></d-footnote>');
    dtfn.html(text);
    $(this).replaceWith(dtfn);
  });
  // remove footnotes
  $('.footnotes').remove();

  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    var id = $(this).attr('id');
    $('.d-toc a[href="#' + id + '"]').parent().remove();
    appendix = true;
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
  });

  // show d-appendix if we have appendix content
  $("d-appendix").css('display', appendix ? 'grid' : 'none');

  // replace code blocks with d-code
  $('pre>code').each(function(i, val) {
    var code = $(this);
    var pre = code.parent();
    var clz = "";
    var language = pre.attr('class');
    if (language) {
      // map unknown languages to "clike" (without this they just dissapear)
      if ($.inArray(language, ["bash", "clike", "css", "go", "html",
                               "javascript", "js", "julia", "lua", "markdown",
                               "markup", "mathml", "python", "svg", "xml"]) == -1)
        language = "clike";
      language = ' language="' + language + '"';
      var dt_code = $('<d-code block' + language + clz + '></d-code>');
      dt_code.text(code.text());
      pre.replaceWith(dt_code);
    } else {
      code.addClass('text-output').unwrap().changeElementType('pre');
    }
  });

  // localize layout chunks to just output
  $('.layout-chunk').each(function(i, val) {

    // capture layout
    var layout = $(this).attr('data-layout');

    // apply layout to markdown level block elements
    var elements = $(this).children().not('d-code, pre.text-output, script');
    elements.each(function(i, el) {
      var layout_div = $('<div class="' + layout + '"></div>');
      if (layout_div.hasClass('shaded')) {
        var shaded_content = $('<div class="shaded-content"></div>');
        $(this).wrap(shaded_content);
        $(this).parent().wrap(layout_div);
      } else {
        $(this).wrap(layout_div);
      }
    });


    // unwrap the layout-chunk div
    $(this).children().unwrap();
  });

  // load distill framework
  load_distill_framework();

  // wait for window.distillRunlevel == 4 to do post processing
  function distill_post_process() {

    if (!window.distillRunlevel || window.distillRunlevel < 4)
      return;

    // hide author/affiliations entirely if we have no authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
    if (!have_authors)
      $('d-byline').addClass('hidden');

    // table of contents
    if (have_authors) // adjust border if we are in authors
      $('.d-toc').parent().addClass('d-article-with-toc');

    // strip links that point to #
    $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

    // hide elements of author/affiliations grid that have no value
    function hide_byline_column(caption) {
      $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
    }

    // affiliations
    var have_affiliations = false;
    for (var i = 0; i<front_matter.authors.length; ++i) {
      var author = front_matter.authors[i];
      if (author.affiliation !== "&nbsp;") {
        have_affiliations = true;
        break;
      }
    }
    if (!have_affiliations)
      $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

    // published date
    if (!front_matter.publishedDate)
      hide_byline_column("Published");

    // document object identifier
    var doi = $('d-byline').find('h3:contains("DOI")');
    var doi_p = doi.next().empty();
    if (!front_matter.doi) {
      // if we have a citation and valid citationText then link to that
      if ($('#citation').length > 0 && front_matter.citationText) {
        doi.html('Citation');
        $('<a href="#citation"></a>')
          .text(front_matter.citationText)
          .appendTo(doi_p);
      } else {
        hide_byline_column("DOI");
      }
    } else {
      $('<a></a>')
         .attr('href', "https://doi.org/" + front_matter.doi)
         .html(front_matter.doi)
         .appendTo(doi_p);
    }

     // change plural form of authors/affiliations
    if (front_matter.authors.length === 1) {
      var grid = $('.authors-affiliations');
      grid.children('h3:contains("Authors")').text('Author');
      grid.children('h3:contains("Affiliations")').text('Affiliation');
    }

    // inject pre code styles (can't do this with a global stylesheet b/c a shadow root is used)
    $('d-code').each(function(i, val) {
      var style = document.createElement('style');
      style.innerHTML = 'pre code { padding-left: 10px; font-size: 12px; border-left: 2px solid rgba(0,0,0,0.1); } ' +
                        '@media(min-width: 768px) { pre code { padding-left: 18px; font-size: 14px; } }';
      if (this.shadowRoot)
        this.shadowRoot.appendChild(style);
    });

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // clear polling timer
    clearInterval(tid);

    // show body now that everything is ready
    on_load_complete();
  }

  var tid = setInterval(distill_post_process, 50);
  distill_post_process();

}

function init_downlevel() {

  init_common();

   // insert hr after d-title
  $('.d-title').after($('<hr class="section-separator"/>'));

  // check if we have authors
  var front_matter = JSON.parse($("#distill-front-matter").html());
  var have_authors = front_matter.authors && front_matter.authors.length > 0;

  // manage byline/border
  if (!have_authors)
    $('.d-byline').remove();
  $('.d-byline').after($('<hr class="section-separator"/>'));
  $('.d-byline a').remove();

  // remove toc
  $('.d-toc-header').remove();
  $('.d-toc').remove();
  $('.d-toc-separator').remove();

  // move appendix elements
  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
  });


  // inject headers into references and footnotes
  var refs_header = $('<h3></h3>');
  refs_header.text('References');
  $('#refs').prepend(refs_header);

  var footnotes_header = $('<h3></h3');
  footnotes_header.text('Footnotes');
  $('.footnotes').children('hr').first().replaceWith(footnotes_header);

  // move appendix-bottom entries to the bottom
  $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
  $('.appendix-bottom').remove();

  // remove appendix if it's empty
  if ($('.d-appendix').children().length === 0)
    $('.d-appendix').remove();

  // prepend separator above appendix
  $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

  // trim code
  $('pre>code').each(function(i, val) {
    $(this).html($.trim($(this).html()));
  });

  // move posts-container right before article
  $('.posts-container').insertBefore($('.d-article'));

  $('body').addClass('downlevel');

  on_load_complete();
}


function init_common() {

  // jquery plugin to change element types
  (function($) {
    $.fn.changeElementType = function(newType) {
      var attrs = {};

      $.each(this[0].attributes, function(idx, attr) {
        attrs[attr.nodeName] = attr.nodeValue;
      });

      this.replaceWith(function() {
        return $("<" + newType + "/>", attrs).append($(this).contents());
      });
    };
  })(jQuery);

  // prevent underline for linked images
  $('a > img').parent().css({'border-bottom' : 'none'});

  // mark non-body figures created by knitr chunks as 100% width
  $('.layout-chunk').each(function(i, val) {
    var figures = $(this).find('img, .html-widget');
    if ($(this).attr('data-layout') !== "l-body") {
      figures.css('width', '100%');
    } else {
      figures.css('max-width', '100%');
      figures.filter("[width]").each(function(i, val) {
        var fig = $(this);
        fig.css('width', fig.attr('width') + 'px');
      });

    }
  });

  // auto-append index.html to post-preview links in file: protocol
  // and in rstudio ide preview
  $('.post-preview').each(function(i, val) {
    if (window.location.protocol === "file:")
      $(this).attr('href', $(this).attr('href') + "index.html");
  });

  // get rid of index.html references in header
  if (window.location.protocol !== "file:") {
    $('.distill-site-header a[href]').each(function(i,val) {
      $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
    });
  }

  // add class to pandoc style tables
  $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
  $('.kable-table').children('table').addClass('pandoc-table');

  // add figcaption style to table captions
  $('caption').parent('table').addClass("figcaption");

  // initialize posts list
  if (window.init_posts_list)
    window.init_posts_list();

  // implmement disqus comment link
  $('.disqus-comment-count').click(function() {
    window.headroom_prevent_pin = true;
    $('#disqus_thread').toggleClass('hidden');
    if (!$('#disqus_thread').hasClass('hidden')) {
      var offset = $(this).offset();
      $(window).resize();
      $('html, body').animate({
        scrollTop: offset.top - 35
      });
    }
  });
}

document.addEventListener('DOMContentLoaded', function() {
  if (is_downlevel_browser())
    init_downlevel();
  else
    window.addEventListener('WebComponentsReady', init_distill);
});

</script>

<!--/radix_placeholder_distill-->
  <script src="../../site_libs/jquery-1.11.3/jquery.min.js"></script>
  <script src="../../site_libs/bowser-1.9.3/bowser.min.js"></script>
  <script src="../../site_libs/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="../../site_libs/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-75406624-1"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-75406624-1');
</script>
<style type="text/css">
d-article {
    font-weight: 300;
}

d-code {
    background: #f7f7f7;
}

pre.text-output {
    color: #d2a963;
    background: #2f2f2f;
    padding: 10px;
}

.distill-site-nav {
    background-color: #268bd2;
}

.distill-site-header .title {
    font-size: 20px;
    font-weight: bolder;
}

d-appendix {
    display: none !important;
}
</style>
<!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Usando o Pytorch no R: Treinando o Seefood","description":"Neste post iremos testar o uso do Pytorch no R com o auxílio do pacote reticulate, que permite a utilização de bibliotecas do Python diretamente no R. Isso ajuda a evitar (em parte) aquela disputa entre o R e o Python, uma vez que você pode usar o melhor de cada. Como exemplo, iremos treinar uma classificador de imagens que é a base do aplicativo Seefood que fez fama no seriado Silicon Valley da HBO.","authors":[{"author":"Paulo Felipe Alencar","authorURL":"#","affiliation":"&nbsp;","affiliationURL":"#"}],"publishedDate":"2020-04-27T00:00:00.000-03:00","citationText":"Alencar, 2020"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<header class="header header--fixed" role="banner">
<nav class="distill-site-nav distill-site-header">
<div class="nav-left">
<a href="../../index.html" class="title">Fulljoin</a>
</div>
<div class="nav-right">
<div class="nav-dropdown">
<button class="nav-dropbtn">
Labs!
 
<span class="down-arrow">&#x25BE;</span>
</button>
<div class="nav-dropdown-content">
<a href="../../dashboard_pnad.html">Dashboard PNAD continua</a>
</div>
</div>
<a href="../../index.html">Posts</a>
<a href="../../about.html">Autores</a>
<a href="javascript:void(0);" class="nav-toggle">&#9776;</a>
</div>
</nav>
</header>
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Usando o Pytorch no R: Treinando o Seefood</h1>
<p>Neste post iremos testar o uso do Pytorch no R com o auxílio do pacote reticulate, que permite a utilização de bibliotecas do Python diretamente no R. Isso ajuda a evitar (em parte) aquela disputa entre o R e o Python, uma vez que você pode usar o melhor de cada. Como exemplo, iremos treinar uma classificador de imagens que é a base do aplicativo Seefood que fez fama no seriado Silicon Valley da HBO.</p>
</div>

<div class="d-byline">
  
  Paulo Felipe Alencar
  
<br/>04-27-2020
</div>

<div class="d-article">
<h2 id="introducao">Introdução</h2>
<p>O Python é a principal linguagem hoje para machine learning, e isso, infelizmente, não tem discussão. Contudo, com o pacote <code>reticulate</code>, é possível utilizar diretamente as biliotecas do Python no R sem grandes problemas. Isto é, uma vez que você tenha instalado tudo que é necessário. A função <code>install_miniconda()</code> ajuda no processo. No entanto, é preciso também instalar o Pytorch no ambiente que será utilizado pelo reticulate. Na minha máquina (e o padrão é assim), utilizo o ambiente <code>r-reticulate</code>.</p>
<p>Para exemplificar o uso do Pytorch, neste post será treinado um modelo que dá origem a aplicação Seefood que ficou famosa no seriado Silicon Valley da HBO. Esse modelo consiste em classificar uma imagem de comida em “hot dog” ou “not hot dog”. Em resumo, conforme <a href="https://silicon-valley.fandom.com/wiki/SeeFood">essa wiki</a>, a história pode ser resumida da seguinte forma:</p>
<blockquote>
<p>SeeFood was a pitch made up in the conference room by Erlich. It was supposed to be Shazam for food, but development stopped after the algorithm could only detect hot dogs. Erlich sold his equity before SeeFood was bought by Periscope for 30 million dollars making Jian-Yang “a very rich man”.</p>
</blockquote>
<p>O código desse post segue em grande parte o <a href="https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html">tutorial</a> disponível no portal do Pytorch.</p>
<h2 id="pacotes-e-modulos">Pacotes e Módulos</h2>
<p>Aqui estão listados os pacotes do R e bibliotecas do Python que iremos utilizar neste post. As biblotecas do Python que serão utilizadas são: <code>torch</code>, <code>torchvision</code>, <code>numpy</code> e <code>copy</code>.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
library(reticulate)
library(imager)
library(glue)
library(tidyverse)
library(zeallot)

# Bibliotecas e módulos do python
py &lt;- import_builtins()
torch &lt;- import(&quot;torch&quot;)
torchvision &lt;- import(&quot;torchvision&quot;)
np &lt;- import(&quot;numpy&quot;)
copy &lt;- import(&quot;copy&quot;)

transforms &lt;- torchvision$transforms
datasets &lt;- torchvision$datasets
models &lt;- torchvision$models
optim &lt;- torch$optim
nn &lt;- torch$nn
F &lt;- torch$nn$functional</code></pre>
</div>
<h2 id="dados">Dados</h2>
<p>Os dados para esse post estão disponívels no Kaggle <a href="https://www.kaggle.com/dansbecker/hot-dog-not-hot-dog/data">neste link</a>. Foram utilizadas as imagens da pasta <code>seefood</code>. As imagens estão incialmente separadas apenas em treino e teste. Iremos, adicionalmente, criar a pasta validação e copiar algumas imagens da pasta de teste para essa nova pasta.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
data_dir &lt;- &quot;../../dados/seefood&quot;

if(!dir.exists(file.path(data_dir, &quot;valid&quot;))){
  dir.create(file.path(data_dir, &quot;valid&quot;))
  dir.create(file.path(data_dir, &quot;valid/hot_dog&quot;))
  dir.create(file.path(data_dir, &quot;valid/not_hot_dog&quot;))

  classes &lt;- c(&quot;hot_dog&quot;, &quot;not_hot_dog&quot;)
  for(classe in classes){
    images &lt;- list.files(file.path(data_dir, &quot;test&quot;, classe))
    set.seed(39031)
    images &lt;- sample(images, 75)
    for(image in images){
      file.copy(
        from = file.path(file.path(data_dir, &quot;test&quot;, classe, image)),
        to = file.path(file.path(data_dir, &quot;valid&quot;, classe, image))
      )
      file.remove(file.path(file.path(data_dir, &quot;test&quot;, classe, image)))
    }
  }
}</code></pre>
</div>
<h2 id="dataloaders">Dataloaders</h2>
<p>Antes de definir propriamente os dataloaders, o código abaixo crias os “transforms” que na prática consistem em pré-processamentos das imagens. Apesar de existir uma enorme variedade de possibilidades, no código abaixo apenas redimensionamos as imagens e normalizamos os pixels para que eles assumam valores entre -1 e 1.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
data_trasnforms &lt;- list(
  train = transforms$Compose(
    list(
      transforms$Resize(c(256L, 256L)),
      transforms$ToTensor(),
      transforms$Normalize(c(0.5, 0.5, 0.5), c(0.5, 0.5, 0.5))
    )
  ),
  valid = transforms$Compose(
    list(      
      transforms$Resize(c(256L, 256L)),
      transforms$ToTensor(),
      transforms$Normalize(c(0.5, 0.5, 0.5), c(0.5, 0.5, 0.5))
    )
  ),
  test = transforms$Compose(
    list(
      transforms$Resize(c(256L, 256L)),
      transforms$ToTensor(),
      transforms$Normalize(c(0.5, 0.5, 0.5), c(0.5, 0.5, 0.5))
    )
  )
)</code></pre>
</div>
<p>O código abaixo cria os dataloaders, que são os objetos que fornecerão os dados ao modelo que será treinado.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
# Dataloaders ---------------------------------------------------------------
sets &lt;- c(&quot;train&quot;, &quot;valid&quot;, &quot;test&quot;)

image_datasets &lt;- map(sets, ~ {
  datasets$ImageFolder(
    file.path(data_dir, .x),
    data_trasnforms[[.x]]
  )
}) %&gt;%
  setNames(sets)

dataloaders &lt;- map(sets, ~{
  torch$utils$data$DataLoader(
    image_datasets[[.x]],
    batch_size = 8L,
    shuffle = TRUE,
    num_workers = 4L
  )
}) %&gt;%
  setNames(sets)

dataset_sizes &lt;- map_dbl(sets, ~ {
  py$len(image_datasets[[.x]])
}) %&gt;%
  setNames(sets)

print(dataset_sizes)</code></pre>
<pre><code>
train valid  test 
  498   150   350 </code></pre>
</div>
<p>Abaixo mostramos uma amostra das imagens que formam esse dataset.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
class_names &lt;- image_datasets[[&#39;train&#39;]]$classes

# Visualizando algumas imagens -----------------------------------------------
iter_train &lt;- py$iter(dataloaders[[&quot;train&quot;]])
c(images, labels) %&lt;-% iter_next(iter_train)
images &lt;- images$numpy()
labels &lt;- labels$numpy()
labels &lt;- class_names[labels + 1]

layout(matrix(1:4, 2, 2))
for(i in 1:4){
  images[i, , , , drop = FALSE] %&gt;%
    aperm(c(3, 4, 1, 2)) %&gt;%
    as.cimg() %&gt;% 
    plot(main = labels[i])
}</code></pre>
<p><img src="usando-o-pytorch-no-r-treinando-o-seefood_files/figure-html5/unnamed-chunk-5-1.png" width="624" /></p>
</div>
<h2 id="funcao-para-treinamento-do-modelo">Função para Treinamento do Modelo</h2>
<p>O processo de treinamento é customizado. Isto é, define-se cada passo do processo na função de treinamento (<code>train_model</code>). Apesar de ser a minha primeira experiência com o Pytorch, achei o processo bem intuitivo e de fácil definição, sendo similar ao processo de treinamento customizado do tensorflow. Basicamente, o processo é o seguinte:</p>
<ul>
<li>Fase de treinamento:
<ul>
<li>Para um batch de imagens, são computadas as predições do modelo.</li>
<li>As predições são comparadas com os rótulos observados (reais) e é a função de perda (loss) é computada</li>
<li>Com o valor da função perda calculado, os gradientes são calculados e aplicados para atualização dos pesos (parâmetros) do modelo.</li>
</ul></li>
<li>Fase de validação:
<ul>
<li>Para um batch de imagens, são computadas as predições do modelo.</li>
<li>Nessa fase, os gradientes não são computados</li>
</ul></li>
</ul>
<p>Ao final de cada “epoch”, são computados os valores finais da função de perda e da acurácia para os dados de treino e de validação.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
train_model &lt;- function(model, criterion, optimizer, scheduler, num_epochs = 25){

  # Guarda os valores dos pesos e da acurácia para a &quot;melhor&quot; epoch
  best_model_wts = copy$deepcopy(model$state_dict())
  best_acc = 0

  for (epoch in 1:num_epochs) {
    cat(glue(&quot;Epoch {epoch}/{num_epochs}&quot;), &quot;\n&quot;)
    cat(&quot;-----------------------------\n&quot;)
    
    for (phase in c(&quot;train&quot;, &quot;valid&quot;)) {
      if (phase == &quot;train&quot;) {
        model$train()
      } else {
        model$eval()
      }

      running_loss &lt;- 0
      running_corrects &lt;- 0

      iter_data &lt;- py$iter(dataloaders[[phase]])
      
      while (TRUE) {
        data &lt;- iter_next(iter_data)
        if (is.null(data)) {          
          break
        }
      
        inputs &lt;- data[[1]]
        inputs &lt;- inputs$to(device)
        labels &lt;- data[[2]]
        labels &lt;- labels$to(device)

        optimizer$zero_grad()
      
        with(torch$set_grad_enabled(phase == &quot;train&quot;), {
          outputs &lt;- model(inputs)
          preds &lt;- torch$max(outputs, 1L)$indices
          loss &lt;- criterion(outputs, labels)
      
          # backward + optimize only if in training phase
          if (phase == &quot;train&quot;) {
            loss$backward()
            optimizer$step()
          }
        })
      
        running_loss &lt;- running_loss + loss$item() * inputs$size(0L)
        running_corrects &lt;- running_corrects + sum(preds$cpu()$numpy() == labels$cpu()$numpy())
      }
      
      if (phase == &quot;train&quot;) {
        scheduler$step()
      }

      epoch_loss &lt;- running_loss / dataset_sizes[[phase]]
      epoch_acc &lt;- running_corrects / dataset_sizes[[phase]]

      cat(glue(&quot;{phase} Loss: {round(epoch_loss,4)} Acc.: {round(epoch_acc, 4)}&quot;), &quot;\n&quot;)

      if (phase == &quot;valid&quot; &amp; epoch_acc &gt; best_acc) {
        best_acc &lt;- epoch_acc
        best_model_wts &lt;- copy$deepcopy(model$state_dict())
      }      
    }   
  }

  model$load_state_dict(best_model_wts)

  cat(&quot;-----------------------------\n&quot;)
  cat(glue(&quot;Best val Acc: {round(best_acc, 4)}&quot;), &quot;\n&quot;)

  return(model)

}</code></pre>
</div>
<h2 id="defining-o-modelo">Defining o modelo</h2>
<p>Aqui utilizamos uma técnica conhecida como Transfer Learning. Isto é, utilizamos um modelo que foi pré-treinado em uma base maior e que já “aprendeu” a extrair features das imagens para auxiliar no treinamento do nosso modelo. Na prática iremos só redimensionar a última camada para que o output seja de dimensão 2 (número de classes da nossa base) e treinar o modelo mais um pouco para que ele se ajuste melhor à nossa tarefa.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
model_ft &lt;- models$resnet34(pretrained = TRUE)
num_ftrs &lt;- model_ft$fc$in_features
model_ft$fc &lt;- nn$Linear(num_ftrs, 2L)

device &lt;- torch$device(&quot;cuda:0&quot;)
model_ft &lt;- model_ft$to(device)
criterion &lt;- nn$CrossEntropyLoss()
optimizer_ft = optim$AdamW(model_ft$parameters(), lr = 5e-5)
lr_scheduler &lt;- optim$lr_scheduler
exp_lr_scheduler = lr_scheduler$StepLR(optimizer_ft, step_size = 5L, gamma = 0.1)

model_ft &lt;- train_model(
  model_ft,
  criterion,
  optimizer_ft,
  exp_lr_scheduler,
  num_epochs = 25L
)</code></pre>
<pre><code>
Epoch 1/25 
-----------------------------
train Loss: 0.4035 Acc.: 0.8173 
valid Loss: 0.2337 Acc.: 0.9133 
Epoch 2/25 
-----------------------------
train Loss: 0.1059 Acc.: 0.9659 
valid Loss: 0.2374 Acc.: 0.9133 
Epoch 3/25 
-----------------------------
train Loss: 0.1241 Acc.: 0.9518 
valid Loss: 0.3299 Acc.: 0.8867 
Epoch 4/25 
-----------------------------
train Loss: 0.1034 Acc.: 0.9618 
valid Loss: 0.3381 Acc.: 0.8867 
Epoch 5/25 
-----------------------------
train Loss: 0.1147 Acc.: 0.9659 
valid Loss: 0.27 Acc.: 0.9067 
Epoch 6/25 
-----------------------------
train Loss: 0.0848 Acc.: 0.9598 
valid Loss: 0.2389 Acc.: 0.9133 
Epoch 7/25 
-----------------------------
train Loss: 0.0744 Acc.: 0.9719 
valid Loss: 0.2367 Acc.: 0.9067 
Epoch 8/25 
-----------------------------
train Loss: 0.0636 Acc.: 0.9819 
valid Loss: 0.2176 Acc.: 0.9267 
Epoch 9/25 
-----------------------------
train Loss: 0.0528 Acc.: 0.988 
valid Loss: 0.2287 Acc.: 0.9133 
Epoch 10/25 
-----------------------------
train Loss: 0.0298 Acc.: 0.99 
valid Loss: 0.2217 Acc.: 0.92 
Epoch 11/25 
-----------------------------
train Loss: 0.0408 Acc.: 0.9859 
valid Loss: 0.2257 Acc.: 0.9133 
Epoch 12/25 
-----------------------------
train Loss: 0.0974 Acc.: 0.9679 
valid Loss: 0.2261 Acc.: 0.92 
Epoch 13/25 
-----------------------------
train Loss: 0.0506 Acc.: 0.9859 
valid Loss: 0.2233 Acc.: 0.92 
Epoch 14/25 
-----------------------------
train Loss: 0.0674 Acc.: 0.9739 
valid Loss: 0.2281 Acc.: 0.92 
Epoch 15/25 
-----------------------------
train Loss: 0.0396 Acc.: 0.988 
valid Loss: 0.2207 Acc.: 0.9133 
Epoch 16/25 
-----------------------------
train Loss: 0.0513 Acc.: 0.988 
valid Loss: 0.2126 Acc.: 0.9267 
Epoch 17/25 
-----------------------------
train Loss: 0.0468 Acc.: 0.9859 
valid Loss: 0.2252 Acc.: 0.9133 
Epoch 18/25 
-----------------------------
train Loss: 0.0724 Acc.: 0.9699 
valid Loss: 0.2303 Acc.: 0.9133 
Epoch 19/25 
-----------------------------
train Loss: 0.0806 Acc.: 0.9679 
valid Loss: 0.2234 Acc.: 0.92 
Epoch 20/25 
-----------------------------
train Loss: 0.0859 Acc.: 0.9679 
valid Loss: 0.2175 Acc.: 0.9133 
Epoch 21/25 
-----------------------------
train Loss: 0.0492 Acc.: 0.9839 
valid Loss: 0.2034 Acc.: 0.9333 
Epoch 22/25 
-----------------------------
train Loss: 0.063 Acc.: 0.9779 
valid Loss: 0.2182 Acc.: 0.9267 
Epoch 23/25 
-----------------------------
train Loss: 0.0321 Acc.: 0.992 
valid Loss: 0.2305 Acc.: 0.9067 
Epoch 24/25 
-----------------------------
train Loss: 0.0453 Acc.: 0.99 
valid Loss: 0.2087 Acc.: 0.9267 
Epoch 25/25 
-----------------------------
train Loss: 0.0421 Acc.: 0.99 
valid Loss: 0.2194 Acc.: 0.9133 
-----------------------------
Best val Acc: 0.9333 </code></pre>
</div>
<h2 id="plotando-predicoes">Plotando predições</h2>
<p>Agora vamos ver como o nosso classificador se sai:</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
iter_test &lt;- py$iter(dataloaders[[&quot;test&quot;]])
c(images, labels) %&lt;-% iter_next(iter_test)
images &lt;- images$to(device)
preds &lt;- model_ft(images)
preds &lt;- torch$max(preds, 1L)$indices
preds &lt;- preds$cpu()$numpy()
preds &lt;- class_names[preds + 1]
images &lt;- images$cpu()$numpy()

layout(matrix(1:4, 2, 2))
for(i in 1:4){
  images[i, , , , drop = FALSE] %&gt;%
    aperm(c(3, 4, 1, 2)) %&gt;%
    as.cimg() %&gt;%
    plot(main = glue(&quot;Predição: {preds[i]}&quot;))
}</code></pre>
<p><img src="usando-o-pytorch-no-r-treinando-o-seefood_files/figure-html5/unnamed-chunk-8-1.png" width="624" /></p>
</div>
<h2 id="resultado-na-base-de-teste">Resultado na base de teste</h2>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
test_acc &lt;- 0
running_corrects &lt;- 0
invisible(model_ft$eval())
N &lt;- dataset_sizes[[&quot;test&quot;]]
iter_data &lt;- py$iter(dataloaders[[&quot;test&quot;]])
with(torch$no_grad(), {
  while (TRUE) {
    data &lt;- iter_next(iter_data)
    if (is.null(data)) {
      break
    }

    inputs &lt;- data[[1]]
    inputs &lt;- inputs$to(device)
    labels &lt;- data[[2]]
    labels &lt;- labels$to(device)
    outputs &lt;- model_ft(inputs)
    preds &lt;- torch$max(outputs, 1L)$indices

    running_corrects &lt;- running_corrects + sum(preds$cpu()$numpy() == labels$cpu()$numpy())

  }
  cat(&quot;-----------------------------\n&quot;)
  cat(glue(&quot;Test Acc: {round(running_corrects/N, 4)}&quot;), &quot;\n&quot;)
})</code></pre>
<pre><code>
-----------------------------
Test Acc: 0.94 </code></pre>
</div>
<p>Nosso modelo conseguiu atingir a acurácia de 94,0%!</p>
<p>Com isso, fechamos esse post! A ideia era mostrar que pode-se usar facilmente uma biblioteca em Python no R com a ajuda do reticulate. Dessa forma, não precisamos nos limitar a uma linguagem única e aproveitar o melhor de cada!</p>
<div style="width:100%;height:0;padding-bottom:75%;position:relative;">
<iframe src="https://giphy.com/embed/MuE0xWbEohUrxbm77r" width="100%" height="100%" style="position:absolute" frameBorder="0" class="giphy-embed" allowFullScreen>
</iframe>
</div>
<p>
<a href="https://giphy.com/gifs/hello-hi-waving-MuE0xWbEohUrxbm77r">via GIPHY</a>
</p>
<!--radix_placeholder_article_footer-->
<div class="article-footer">
  <p class="social_footer">
    <span class="disqus-comments">
      <i class="fas fa-comments"></i>
      &nbsp;
      <span class="disqus-comment-count" data-disqus-identifier="posts/2020-04-27-usando-o-pytorch-no-r-treinando-o-seefood/">Comment on this article</span>
    </span>
    <span class="article-sharing">
      Share: &nbsp;
      <a href="https://twitter.com/share?text=Usando%20o%20Pytorch%20no%20R%3A%20Treinando%20o%20Seefood&amp;url=https%3A%2F%2Fwww.fulljoin.com.br%2Fposts%2F2020-04-27-usando-o-pytorch-no-r-treinando-o-seefood%2F">
        <i class="fab fa-twitter"></i>
      </a>
      <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Fwww.fulljoin.com.br%2Fposts%2F2020-04-27-usando-o-pytorch-no-r-treinando-o-seefood%2F&amp;title=Usando%20o%20Pytorch%20no%20R%3A%20Treinando%20o%20Seefood">
        <i class="fab fa-linkedin"></i>
      </a>
      <a href="https://www.facebook.com/sharer/sharer.php?s=100&amp;p[url]=https%3A%2F%2Fwww.fulljoin.com.br%2Fposts%2F2020-04-27-usando-o-pytorch-no-r-treinando-o-seefood%2F">
        <i class="fab fa-facebook"></i>
      </a>
    </span>
  </p>
  <script id="dsq-count-scr" src="https://fulljoin.disqus.com/count.js" async></script>
  <div id="disqus_thread" class="hidden"></div>
  <script>
var disqus_config = function () {
  this.page.url = 'https://www.fulljoin.com.br/posts/2020-04-27-usando-o-pytorch-no-r-treinando-o-seefood/';
  this.page.identifier = 'posts/2020-04-27-usando-o-pytorch-no-r-treinando-o-seefood/';
};
(function() {
  var d = document, s = d.createElement('script');
  s.src = 'https://fulljoin.disqus.com/embed.js';
  s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
})();
</script>
</div>
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>


<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom">
  <h3 id="citation">Citation</h3>
  <p>For attribution, please cite this work as</p>
  <pre class="citation-appendix short">Alencar (2020, April 27). Fulljoin: Usando o Pytorch no R: Treinando o Seefood. Retrieved from https://www.fulljoin.com.br/posts/2020-04-27-usando-o-pytorch-no-r-treinando-o-seefood/</pre>
  <p>BibTeX citation</p>
  <pre class="citation-appendix long">@misc{alencar2020usando,
  author = {Alencar, Paulo Felipe},
  title = {Fulljoin: Usando o Pytorch no R: Treinando o Seefood},
  url = {https://www.fulljoin.com.br/posts/2020-04-27-usando-o-pytorch-no-r-treinando-o-seefood/},
  year = {2020}
}</pre>
</div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<div class="distill-site-nav distill-site-footer">
  <p>Gostou do blog? <u><a href="https://www.buymeacoffee.com/LYcEmgQ">Pague-nos um cafezinho!</a></u></p>
</div>
<!--/radix_placeholder_navigation_after_body-->


</body>

</html>
