<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="radix" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

  <!--radix_placeholder_meta_tags-->
  <title>Classificando Comentários Tóxicos com o R</title>
  
  <meta property="description" itemprop="description" content="Nesse post, vamos criar um classificador de comentÃ¡rios tÃ³xicos a partir de uma&#10;base de dados disponibilizada em uma competiÃ§Ã£o do Kaggle. SerÃ£o utilizadas &#10;tÃ©cnicas chamadas de bag-of-words e tf-idf."/>
  
  
  <!--  https://schema.org/Article -->
  <meta property="article:published" itemprop="datePublished" content="2018-11-18"/>
  <meta property="article:created" itemprop="dateCreated" content="2018-11-18"/>
  <meta name="article:author" content="Paulo Felipe Alencar"/>
  
  <!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
  <meta property="og:title" content="Classificando Comentários Tóxicos com o R"/>
  <meta property="og:type" content="article"/>
  <meta property="og:description" content="Nesse post, vamos criar um classificador de comentÃ¡rios tÃ³xicos a partir de uma&#10;base de dados disponibilizada em uma competiÃ§Ã£o do Kaggle. SerÃ£o utilizadas &#10;tÃ©cnicas chamadas de bag-of-words e tf-idf."/>
  <meta property="og:locale" content="en_US"/>
  
  <!--  https://dev.twitter.com/cards/types/summary -->
  <meta property="twitter:card" content="summary"/>
  <meta property="twitter:title" content="Classificando Comentários Tóxicos com o R"/>
  <meta property="twitter:description" content="Nesse post, vamos criar um classificador de comentÃ¡rios tÃ³xicos a partir de uma&#10;base de dados disponibilizada em uma competiÃ§Ã£o do Kaggle. SerÃ£o utilizadas &#10;tÃ©cnicas chamadas de bag-of-words e tf-idf."/>
  
  <!--/radix_placeholder_meta_tags-->
  <!--radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-rmarkdown-metadata">
  {"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","date","output","categories","draft"]}},"value":[{"type":"character","attributes":{},"value":["Classificando Comentários Tóxicos com o R"]},{"type":"character","attributes":{},"value":["Nesse post, vamos criar um classificador de comentários tóxicos a partir de uma\nbase de dados disponibilizada em uma competição do Kaggle. Serão utilizadas \ntécnicas chamadas de bag-of-words e tf-idf.\n"]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url"]}},"value":[{"type":"character","attributes":{},"value":["Paulo Felipe Alencar"]},{"type":"character","attributes":{},"value":["https://github.com/paulofelipe"]}]}]},{"type":"character","attributes":{},"value":["11-18-2018"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["radix::radix_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained"]}},"value":[{"type":"logical","attributes":{},"value":[false]}]}]},{"type":"character","attributes":{},"value":["NLP","Kaggle","Aprendizado de Máquina"]},{"type":"logical","attributes":{},"value":[false]}]}
  </script>
  <!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["classificando-comentrios-txicos_files/bowser-1.9.3/bowser.min.js","classificando-comentrios-txicos_files/distill-2.2.21/template.v2.js","classificando-comentrios-txicos_files/figure-html5/unnamed-chunk-4-1.png","classificando-comentrios-txicos_files/figure-html5/unnamed-chunk-5-1.png","classificando-comentrios-txicos_files/jquery-1.11.3/jquery.min.js","classificando-comentrios-txicos_files/webcomponents-2.0.0/webcomponents.js","dados/subm.csv","dados/test.csv","dados/test_labels.csv","dados/train.csv","imagens/score_kaggle.png"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
  <!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->
  
  <style type="text/css">
  
  body {
    background-color: white;
  }
  
  .pandoc-table {
    width: 100%;
  }
  
  .pandoc-table>caption {
    margin-bottom: 10px;
  }
  
  .pandoc-table th:not([align]) {
    text-align: left;
  }
  
  .pagedtable-footer {
    font-size: 15px;
  }
  
  .html-widget {
    margin-bottom: 2.0em;
  }
  
  .l-screen-inset {
    padding-right: 16px;
  }
  
  .l-screen .caption {
    margin-left: 10px;
  }
  
  .shaded {
    background: rgb(247, 247, 247);
    padding-top: 20px;
    padding-bottom: 20px;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .shaded .html-widget {
    margin-bottom: 0;
    border: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .shaded .shaded-content {
    background: white;
  }
  
  .text-output {
    margin-top: 0;
    line-height: 1.5em;
  }
  
  .hidden {
    display: none !important;
  }
  
  d-article {
    padding-bottom: 30px;
  }
  
  d-appendix {
    padding-top: 30px;
  }
  
  d-article>p>img {
    width: 100%;
  }
  
  d-article iframe {
    border: 1px solid rgba(0, 0, 0, 0.1);
    margin-bottom: 2.0em;
    width: 100%;
  }
  
  figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }
  
  /* CSS for table of contents */
  
  .d-toc {
    color: rgba(0,0,0,0.8);
    font-size: 0.8em;
    line-height: 1em;
  }
  
  .d-toc-header {
    font-size: 0.6rem;
    font-weight: 400;
    color: rgba(0, 0, 0, 0.5);
    text-transform: uppercase;
    margin-top: 0;
    margin-bottom: 1.3em;
  }
  
  .d-toc a {
    border-bottom: none;
  }
  
  .d-toc ul {
    padding-left: 0;
  }
  
  .d-toc li>ul {
    padding-top: 0.8em;
    padding-left: 16px;
    margin-bottom: 0.6em;
  }
  
  .d-toc ul,
  .d-toc li {
    list-style-type: none;
  }
  
  .d-toc li {
    margin-bottom: 0.9em;
  }
  
  .d-toc-separator {
    margin-top: 20px;
    margin-bottom: 2em;
  }
  
  .d-article-with-toc {
    border-top: none;
    padding-top: 0;
  }
  
  
  
  /* Tweak code blocks (note that this CSS is repeated above in an injection
     into the d-code shadow dom) */
  
  pre.d-code code.d-code {
    padding-left: 10px;
    font-size: 12px;
    border-left: 2px solid rgba(0,0,0,0.1);
  }
  
  pre.text-output {
  
    font-size: 12px;
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
  
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
  
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }
  
  @media(min-width: 768px) {
  pre.d-code code.d-code  {
      padding-left: 18px;
      font-size: 14px;
  }
  pre.text-output {
    font-size: 14px;
  }
  }
  
  /* Figure */
  
  .figure {
    position: relative;
    margin-bottom: 2.5em;
    margin-top: 1.5em;
  }
  
  .figure img {
    width: 100%;
  }
  
  .figure .caption {
    color: rgba(0, 0, 0, 0.6);
    font-size: 12px;
    line-height: 1.5em;
  }
  
  .figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }
  
  .figure .caption a {
    color: rgba(0, 0, 0, 0.6);
  }
  
  .figure .caption b,
  .figure .caption strong, {
    font-weight: 600;
    color: rgba(0, 0, 0, 1.0);
  }
  
  
  
  /* Tweak 1000px media break to show more text */
  
  @media(min-width: 1000px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 16px;
    }
  
    .grid {
      grid-column-gap: 16px;
    }
  
    d-article {
      font-size: 1.06rem;
      line-height: 1.7em;
    }
    figure .caption, .figure .caption, figure figcaption {
      font-size: 13px;
    }
  }
  
  @media(min-width: 1180px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 32px;
    }
  
    .grid {
      grid-column-gap: 32px;
    }
  }
  
  
  /* Get the citation styles for the appendix (not auto-injected on render since
     we do our own rendering of the citation appendix) */
  
  d-appendix .citation-appendix,
  .d-appendix .citation-appendix {
    font-size: 11px;
    line-height: 15px;
    border-left: 1px solid rgba(0, 0, 0, 0.1);
    padding-left: 18px;
    border: 1px solid rgba(0,0,0,0.1);
    background: rgba(0, 0, 0, 0.02);
    padding: 10px 18px;
    border-radius: 3px;
    color: rgba(150, 150, 150, 1);
    overflow: hidden;
    margin-top: -12px;
    white-space: pre-wrap;
    word-wrap: break-word;
  }
  
  
  /* Social footer */
  
  .social_footer {
    margin-top: 30px;
    margin-bottom: 0;
    color: rgba(0,0,0,0.67);
  }
  
  .disqus-comments {
    margin-right: 30px;
  }
  
  .disqus-comment-count {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
    cursor: pointer;
  }
  
  #disqus_thread {
    margin-top: 30px;
  }
  
  .article-sharing a {
    border-bottom: none;
    margin-right: 8px;
  }
  
  .article-sharing a:hover {
    border-bottom: none;
  }
  
  .sidebar-section.subscribe {
    font-size: 12px;
    line-height: 1.6em;
  }
  
  .subscribe p {
    margin-bottom: 0.5em;
  }
  
  
  .article-footer .subscribe {
    font-size: 15px;
    margin-top: 45px;
  }
  
  
  /* Improve display for browsers without grid (IE/Edge <= 15) */
  
  .downlevel {
    line-height: 1.6em;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    margin: 0;
  }
  
  .downlevel .d-title {
    padding-top: 6rem;
    padding-bottom: 1.5rem;
  }
  
  .downlevel .d-title h1 {
    font-size: 50px;
    font-weight: 700;
    line-height: 1.1em;
    margin: 0 0 0.5rem;
  }
  
  .downlevel .d-title p {
    font-weight: 300;
    font-size: 1.2rem;
    line-height: 1.55em;
    margin-top: 0;
  }
  
  .downlevel .d-byline {
    padding-top: 0.8em;
    padding-bottom: 0.8em;
    font-size: 0.8rem;
    line-height: 1.8em;
  }
  
  .downlevel .section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .downlevel .d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
    padding-top: 1rem;
    padding-bottom: 2rem;
  }
  
  
  .downlevel .d-appendix {
    padding-left: 0;
    padding-right: 0;
    max-width: none;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.5);
    padding-top: 40px;
    padding-bottom: 48px;
  }
  
  .downlevel .footnotes ol {
    padding-left: 13px;
  }
  
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
    padding-left: 40px;
    padding-right: 40px;
  }
  
  @media(min-width: 768px) {
    .downlevel .base-grid,
    .downlevel .distill-header,
    .downlevel .d-title,
    .downlevel .d-abstract,
    .downlevel .d-article,
    .downlevel .d-appendix,
    .downlevel .distill-appendix,
    .downlevel .d-byline,
    .downlevel .d-footnote-list,
    .downlevel .d-citation-list,
    .downlevel .distill-footer,
    .downlevel .appendix-bottom,
    .downlevel .posts-container {
    padding-left: 150px;
    padding-right: 150px;
    max-width: 900px;
  }
  }
  
  .downlevel pre code {
    display: block;
    border-left: 2px solid rgba(0, 0, 0, .1);
    padding: 0 0 0 20px;
    font-size: 14px;
  }
  
  .downlevel code, .downlevel pre {
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
  
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
  
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }
  
  </style>
  
  <script type="application/javascript">
  
  function is_downlevel_browser() {
    if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                   window.navigator.userAgent)) {
      return true;
    } else {
      return window.load_distill_framework === undefined;
    }
  }
  
  // show body when load is complete
  function on_load_complete() {
  
    // set body to visible
    document.body.style.visibility = 'visible';
  
    // force redraw for leaflet widgets
    if (window.HTMLWidgets) {
      var maps = window.HTMLWidgets.findAll(".leaflet");
      $.each(maps, function(i, el) {
        var map = this.getMap();
        map.invalidateSize();
        map.eachLayer(function(layer) {
          if (layer instanceof L.TileLayer)
            layer.redraw();
        });
      });
    }
  
    // trigger 'shown' so htmlwidgets resize
    $('d-article').trigger('shown');
  }
  
  function init_distill() {
  
    init_common();
  
    // create front matter
    var front_matter = $('<d-front-matter></d-front-matter>');
    $('#distill-front-matter').wrap(front_matter);
  
    // create d-title
    $('.d-title').changeElementType('d-title');
  
    // create d-byline
    var byline = $('<d-byline></d-byline>');
    $('.d-byline').replaceWith(byline);
  
    // create d-article
    var article = $('<d-article></d-article>');
    $('.d-article').wrap(article).children().unwrap();
  
    // move posts container into article
    $('.posts-container').appendTo($('d-article'));
  
    // create d-appendix
    $('.d-appendix').changeElementType('d-appendix');
  
    // create d-bibliography
    var bibliography = $('<d-bibliography></d-bibliography>');
    $('#distill-bibliography').wrap(bibliography);
  
    // flag indicating that we have appendix items
    var appendix = $('.appendix-bottom').children('h3').length > 0;
  
    // replace citations with <d-cite>
    $('.citation').each(function(i, val) {
      appendix = true;
      var cites = $(this).attr('data-cites').split(" ");
      var dt_cite = $('<d-cite></d-cite>');
      dt_cite.attr('key', cites.join());
      $(this).replaceWith(dt_cite);
    });
    // remove refs
    $('#refs').remove();
  
    // replace footnotes with <d-footnote>
    $('.footnote-ref').each(function(i, val) {
      appendix = true;
      var href = $(this).attr('href');
      var id = href.replace('#', '');
      var fn = $('#' + id);
      var fn_p = $('#' + id + '>p');
      fn_p.find('.footnote-back').remove();
      var text = fn_p.html();
      var dtfn = $('<d-footnote></d-footnote>');
      dtfn.html(text);
      $(this).replaceWith(dtfn);
    });
    // remove footnotes
    $('.footnotes').remove();
  
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      var id = $(this).attr('id');
      $('.d-toc a[href="#' + id + '"]').parent().remove();
      appendix = true;
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
    });
  
    // show d-appendix if we have appendix content
    $("d-appendix").css('display', appendix ? 'grid' : 'none');
  
    // replace code blocks with d-code
    $('pre>code').each(function(i, val) {
      var code = $(this);
      var pre = code.parent();
      var clz = "";
      var language = pre.attr('class');
      if (language) {
        // map unknown languages to "clike" (without this they just dissapear)
        if ($.inArray(language, ["bash", "clike", "css", "go", "html",
                                 "javascript", "js", "julia", "lua", "markdown",
                                 "markup", "mathml", "python", "svg", "xml"]) == -1)
          language = "clike";
        language = ' language="' + language + '"';
        var dt_code = $('<d-code block' + language + clz + '></d-code>');
        dt_code.text(code.text());
        pre.replaceWith(dt_code);
      } else {
        code.addClass('text-output').unwrap().changeElementType('pre');
      }
    });
  
    // localize layout chunks to just output
    $('.layout-chunk').each(function(i, val) {
  
      // capture layout
      var layout = $(this).attr('data-layout');
  
      // apply layout to markdown level block elements
      var elements = $(this).children().not('d-code, pre.text-output, script');
      elements.each(function(i, el) {
        var layout_div = $('<div class="' + layout + '"></div>');
        if (layout_div.hasClass('shaded')) {
          var shaded_content = $('<div class="shaded-content"></div>');
          $(this).wrap(shaded_content);
          $(this).parent().wrap(layout_div);
        } else {
          $(this).wrap(layout_div);
        }
      });
  
  
      // unwrap the layout-chunk div
      $(this).children().unwrap();
    });
  
    // load distill framework
    load_distill_framework();
  
    // wait for window.distillRunlevel == 4 to do post processing
    function distill_post_process() {
  
      if (!window.distillRunlevel || window.distillRunlevel < 4)
        return;
  
      // hide author/affiliations entirely if we have no authors
      var front_matter = JSON.parse($("#distill-front-matter").html());
      var have_authors = front_matter.authors && front_matter.authors.length > 0;
      if (!have_authors)
        $('d-byline').addClass('hidden');
  
      // table of contents
      if (have_authors) // adjust border if we are in authors
        $('.d-toc').parent().addClass('d-article-with-toc');
  
      // strip links that point to #
      $('.authors-affiliations').find('a[href="#"]').removeAttr('href');
  
      // hide elements of author/affiliations grid that have no value
      function hide_byline_column(caption) {
        $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
      }
  
      // affiliations
      var have_affiliations = false;
      for (var i = 0; i<front_matter.authors.length; ++i) {
        var author = front_matter.authors[i];
        if (author.affiliation !== "&nbsp;") {
          have_affiliations = true;
          break;
        }
      }
      if (!have_affiliations)
        $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');
  
      // published date
      if (!front_matter.publishedDate)
        hide_byline_column("Published");
  
      // document object identifier
      var doi = $('d-byline').find('h3:contains("DOI")');
      var doi_p = doi.next().empty();
      if (!front_matter.doi) {
        // if we have a citation and valid citationText then link to that
        if ($('#citation').length > 0 && front_matter.citationText) {
          doi.html('Citation');
          $('<a href="#citation"></a>')
            .text(front_matter.citationText)
            .appendTo(doi_p);
        } else {
          hide_byline_column("DOI");
        }
      } else {
        $('<a></a>')
           .attr('href', "https://doi.org/" + front_matter.doi)
           .html(front_matter.doi)
           .appendTo(doi_p);
      }
  
       // change plural form of authors/affiliations
      if (front_matter.authors.length === 1) {
        var grid = $('.authors-affiliations');
        grid.children('h3:contains("Authors")').text('Author');
        grid.children('h3:contains("Affiliations")').text('Affiliation');
      }
  
      // inject pre code styles (can't do this with a global stylesheet b/c a shadow root is used)
      $('d-code').each(function(i, val) {
        var style = document.createElement('style');
        style.innerHTML = 'pre code { padding-left: 10px; font-size: 12px; border-left: 2px solid rgba(0,0,0,0.1); } ' +
                          '@media(min-width: 768px) { pre code { padding-left: 18px; font-size: 14px; } }';
        if (this.shadowRoot)
          this.shadowRoot.appendChild(style);
      });
  
      // move appendix-bottom entries to the bottom
      $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
      $('.appendix-bottom').remove();
  
      // clear polling timer
      clearInterval(tid);
  
      // show body now that everything is ready
      on_load_complete();
    }
  
    var tid = setInterval(distill_post_process, 50);
    distill_post_process();
  
  }
  
  function init_downlevel() {
  
    init_common();
  
     // insert hr after d-title
    $('.d-title').after($('<hr class="section-separator"/>'));
  
    // check if we have authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
  
    // manage byline/border
    if (!have_authors)
      $('.d-byline').remove();
    $('.d-byline').after($('<hr class="section-separator"/>'));
    $('.d-byline a').remove();
  
    // remove toc
    $('.d-toc-header').remove();
    $('.d-toc').remove();
    $('.d-toc-separator').remove();
  
    // move appendix elements
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
    });
  
  
    // inject headers into references and footnotes
    var refs_header = $('<h3></h3>');
    refs_header.text('References');
    $('#refs').prepend(refs_header);
  
    var footnotes_header = $('<h3></h3');
    footnotes_header.text('Footnotes');
    $('.footnotes').children('hr').first().replaceWith(footnotes_header);
  
    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
    $('.appendix-bottom').remove();
  
    // remove appendix if it's empty
    if ($('.d-appendix').children().length === 0)
      $('.d-appendix').remove();
  
    // prepend separator above appendix
    $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));
  
    // trim code
    $('pre>code').each(function(i, val) {
      $(this).html($.trim($(this).html()));
    });
  
    // move posts-container right before article
    $('.posts-container').insertBefore($('.d-article'));
  
    $('body').addClass('downlevel');
  
    on_load_complete();
  }
  
  
  function init_common() {
  
    // jquery plugin to change element types
    (function($) {
      $.fn.changeElementType = function(newType) {
        var attrs = {};
  
        $.each(this[0].attributes, function(idx, attr) {
          attrs[attr.nodeName] = attr.nodeValue;
        });
  
        this.replaceWith(function() {
          return $("<" + newType + "/>", attrs).append($(this).contents());
        });
      };
    })(jQuery);
  
    // prevent underline for linked images
    $('a > img').parent().css({'border-bottom' : 'none'});
  
    // mark non-body figures created by knitr chunks as 100% width
    $('.layout-chunk').each(function(i, val) {
      var figures = $(this).find('img, .html-widget');
      if ($(this).attr('data-layout') !== "l-body") {
        figures.css('width', '100%');
      } else {
        figures.css('max-width', '100%');
        figures.filter("[width]").each(function(i, val) {
          var fig = $(this);
          fig.css('width', fig.attr('width') + 'px');
        });
  
      }
    });
  
    // auto-append index.html to post-preview links in file: protocol
    // and in rstudio ide preview
    $('.post-preview').each(function(i, val) {
      if (window.location.protocol === "file:")
        $(this).attr('href', $(this).attr('href') + "index.html");
    });
  
    // get rid of index.html references in header
    if (window.location.protocol !== "file:") {
      $('.radix-site-header a[href]').each(function(i,val) {
        $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
      });
    }
  
    // add class to pandoc style tables
    $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
    $('.kable-table').children('table').addClass('pandoc-table');
  
    // add figcaption style to table captions
    $('caption').parent('table').addClass("figcaption");
  
    // initialize posts list
    if (window.init_posts_list)
      window.init_posts_list();
  
    // implmement disqus comment link
    $('.disqus-comment-count').click(function() {
      window.headroom_prevent_pin = true;
      $('#disqus_thread').toggleClass('hidden');
      if (!$('#disqus_thread').hasClass('hidden')) {
        var offset = $(this).offset();
        $(window).resize();
        $('html, body').animate({
          scrollTop: offset.top - 35
        });
      }
    });
  }
  
  document.addEventListener('DOMContentLoaded', function() {
    if (is_downlevel_browser())
      init_downlevel();
    else
      window.addEventListener('WebComponentsReady', init_distill);
  });
  
  </script>
  
  <!--/radix_placeholder_distill-->
  <script src="classificando-comentrios-txicos_files/jquery-1.11.3/jquery.min.js"></script>
  <script src="classificando-comentrios-txicos_files/bowser-1.9.3/bowser.min.js"></script>
  <script src="classificando-comentrios-txicos_files/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="classificando-comentrios-txicos_files/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
  <!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Classificando Comentários Tóxicos com o R","description":"Nesse post, vamos criar um classificador de comentários tóxicos a partir de uma\nbase de dados disponibilizada em uma competição do Kaggle. Serão utilizadas \ntécnicas chamadas de bag-of-words e tf-idf.","authors":[{"author":"Paulo Felipe Alencar","authorURL":"https://github.com/paulofelipe","affiliation":"&nbsp;","affiliationURL":"#"}],"publishedDate":"2018-11-18T00:00:00.000-02:00","citationText":"Alencar, 2018"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Classificando Comentários Tóxicos com o R</h1>
<p>Nesse post, vamos criar um classificador de comentários tóxicos a partir de uma base de dados disponibilizada em uma competição do Kaggle. Serão utilizadas técnicas chamadas de bag-of-words e tf-idf.</p>
</div>

<div class="d-byline">
  Paulo Felipe Alencar <a href="https://github.com/paulofelipe" class="uri">https://github.com/paulofelipe</a> 
  
<br/>11-18-2018
</div>

<div class="d-article">
<h2 id="motivacao">Motivação</h2>
<p>A internet é muitas vezes considerada “terra de ninguém”. E um dos problemas mais comums são comentários tóxicos, para não usar outro adjetivo. A moderação desses comentários é uma atividade que surge naturalmente. No entando, pode ser inviável analisar individualmente todos comentários de uma grande plataforma, por exemplo.</p>
<p>Nesse sentido, pode ser útil criar um classificador automático. Dessa forma, será exemplificado como criar um classificador no R. Para isso, utilizaremos os dados do desafio do Kaggle <a href="https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge"><em>Toxic Comment Classification</em></a> Iniciaremos, com uma solução mais simples e em outros posts tentaremos utilizar técnicas mais sofisticadas. Uma lista de soluções pode ser encontrada no <a href="https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion">fórum da competição</a>.</p>
<h2 id="pacotes">Pacotes</h2>
<p>Aqui estão os pacotes que utilizaremos neste post:</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
library(tidyverse)
library(text2vec)
library(purrr)
library(glmnet)</code></pre>
</div>
<h2 id="dados">Dados</h2>
<p>Os dados podem ser baixados <a href="https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data">neste link</a>. Precisaremos de três arquivos: <code>train.csv</code>, <code>test.csv</code> e <code>test_labels.csv</code>. O arquivo <code>test_labels.csv</code> contém os valores que deveriam ter sido previstos na competição. O Kaggle libera esse arquivo depois que a competição é finalizada. Esse arquivo será útil para avaliarmos o nosso modelo.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
# Defina aqui o caminho para a pasta que estão os dados
caminho_dados &lt;- &#39;dados/&#39;
list.files(caminho_dados)</code></pre>
<pre><code>
[1] &quot;subm.csv&quot;        &quot;test.csv&quot;        &quot;test_labels.csv&quot;
[4] &quot;train.csv&quot;      </code></pre>
</div>
<p>Lendo os dados de treinamento:</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
train &lt;- read_csv(file.path(caminho_dados, &#39;train.csv&#39;))
dim(train)</code></pre>
<pre><code>
[1] 159571      8</code></pre>
<pre class="r"><code>
head(train)</code></pre>
<pre><code>
# A tibble: 6 x 8
  id    comment_text toxic severe_toxic obscene threat insult
  &lt;chr&gt; &lt;chr&gt;        &lt;int&gt;        &lt;int&gt;   &lt;int&gt;  &lt;int&gt;  &lt;int&gt;
1 0000~ &quot;Explanatio~     0            0       0      0      0
2 0001~ D&#39;aww! He m~     0            0       0      0      0
3 0001~ Hey man, I&#39;~     0            0       0      0      0
4 0001~ &quot;\&quot;\nMore\n~     0            0       0      0      0
5 0001~ You, sir, a~     0            0       0      0      0
6 0002~ &quot;\&quot;\n\nCong~     0            0       0      0      0
# ... with 1 more variable: identity_hate &lt;int&gt;</code></pre>
</div>
<p>O arquivo <code>train.csv</code> possui 8 colunas e 159.571 observações. A primeira variável é o id, a coluna <code>comment_text</code> traz o texto do comentário e há mais 6 colunas que indicam se comentário foi classificado em uma ou mais categoria de comentário tóxico.</p>
<p>O que seria um comentário tóxico? Quem quiser pode pular essa parte…Tentei mostrar um comentário mais suave.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
set.seed(2031)
train %&gt;% 
  filter(toxic == 1) %&gt;% 
  sample_n(1) %&gt;% 
  pull(comment_text)</code></pre>
<pre><code>
[1] &quot;Wikipedia is too serious an encyclopedia to accommodate your ignorance.&quot;</code></pre>
</div>
<p>A figura abaixo apresenta a proporção de comentários classificados como “tóxico” por categoria de toxicidade. Uma categoria é denominada de “tóxico”, mas estou usando o termo tóxico pra classificar comentário de qualquer uma das categorias.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
train %&gt;% 
  summarise_if(is.numeric, mean) %&gt;% 
  gather(key = classe, value = proporcao) %&gt;% 
  ggplot(aes(x = classe, y = proporcao)) +
  geom_col(fill = &quot;#F56613F1&quot;) +
  scale_y_continuous(labels = scales::percent) +
  theme_minimal() +
  labs(
    title = &quot;Proporção de Comentários Tóxicos por Categoria&quot;,
    y = &quot;Proporção&quot;,
    x = &quot;Categoria&quot;
  )</code></pre>
<p><img src="classificando-comentrios-txicos_files/figure-html5/unnamed-chunk-5-1.png" width="624" /></p>
</div>
<p>O primeiro ponto importante é que existe um desbalanceamento nos dados. Ou seja, a proporção de comentários tóxicos é baixa, principalmente na classe <code>threat</code>.</p>
<h2 id="processando-o-texto---bag-of-words">Processando o texto - Bag-of-Words</h2>
<p>Precisamos converter os textos dos comentários em variáveis (<em>features</em>) que serão utilizadas para treinar o nosso classificador. Uma técnica comum é denominada de bag-of-words, que consiste em criar uma variável para cada palavra do vocabulário e contar quantas vezes aquelas palavra aparece em cada “documento”. Também é possível usar n-gramas, que são combinações de n palavras.</p>
<p>Antes, vamos definir uma função que será usada para preprocessar os comentários.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
limpa_texto &lt;- function(comment){
  tolower(comment) %&gt;% 
    # espaço entre os caracteres especiais
    str_replace_all(&quot;([“”¨«»®´·º½¾¿¡§£₤‘’~])&quot;, &quot; \\1 &quot;) %&gt;% 
    # espaço entre as pontuações
    str_replace_all(&quot;([[:punct:]])&quot;, &quot; \\1 &quot;) %&gt;% 
    # substitui quebra de linha
    str_replace_all(&quot;\\n&quot;, &#39; &#39;)
}

limpa_texto(&quot;teste de processamento!!\n!!&quot;)</code></pre>
<pre><code>
[1] &quot;teste de processamento !  !   !  ! &quot;</code></pre>
</div>
<p>Para fazer a vetorização dos comentários, será utilizado o pacote <code>text2vec</code>. O código abaixo cria o vocabulário. A função <code>space_tokenizer</code> é utilizada como separador de termos para o dicionário. Além disso, são removidas as chamadas <em>stopwords</em>, que são palavras que não adicionam valor na nossa análise.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
it_train &lt;- itoken(
  train$comment_text,
  preprocessor = limpa_texto,
  tokenizer = word_tokenizer,
  id = train$id,
  progressbar = FALSE
)

vocabulario &lt;- create_vocabulary(it_train,
                                 stopwords = tm::stopwords(&#39;en&#39;))
vocabulario</code></pre>
<pre><code>
Number of docs: 159571 
174 stopwords: i, me, my, myself, we, our ... 
ngram_min = 1; ngram_max = 1 
Vocabulary: 
                  term term_count doc_count
     1:     praguepost          1         1
     2:           ht1b          1         1
     3: specialiststhe          1         1
     4:        bucheon          1         1
     5:       wiselius          1         1
    ---                                    
186770:           page      46568     27842
186771:      wikipedia      48627     26997
186772:        article      57776     32157
186773:              t      61126     38759
186774:              s      72705     40795</code></pre>
</div>
<p>O nosso vocabulário possui mais 200.000 palavras. Cada palavra, potencialmente, irá virar uma variável. No entanto, é comum reduzir o vocabulário com o intuito de eficiência. Para reduzir o vocabulário vamos utilizar a função <code>prune_vocabulary()</code>. Além da redução de dimensionalidade do problema, palavras que aparecem em quase todos comentários ou quase nunca, dificilmente serão úteis para separar se o post é tóxico ou não. Abaixo fazemos a redução do vocabulário.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
vocabulario &lt;- prune_vocabulary(
  vocabulary = vocabulario,
  term_count_min = 5,
  doc_proportion_max = 0.9,
  vocab_term_max = 20000
)

vocabulario</code></pre>
<pre><code>
Number of docs: 159571 
174 stopwords: i, me, my, myself, we, our ... 
ngram_min = 1; ngram_max = 1 
Vocabulary: 
            term term_count doc_count
    1:         s      72705     40795
    2:         t      61126     38759
    3:   article      57776     32157
    4: wikipedia      48627     26997
    5:      page      46568     27842
   ---                               
19996: militancy         15        13
19997:       cas         15        14
19998:    sandra         15        15
19999:   pandyan         15         3
20000:    smoked         15        12</code></pre>
</div>
<p>Por fim, é criado o vetorizador.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
toxic_vectorizer &lt;- vocab_vectorizer(vocabulary = vocabulario)</code></pre>
</div>
<p>O vetorizador é usado na função <code>create_dtm()</code> para criar nossa matriz de <em>features</em>. Como a maioria dos elementos da matriz serão zero, utilizamos o formato <code>dgCMatrix</code> para reduzir a necessidade de memória.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
train_dtm &lt;- create_dtm(
  it = it_train,
  vectorizer = toxic_vectorizer,
  type = &#39;dgCMatrix&#39;
)

dim(train_dtm)</code></pre>
<pre><code>
[1] 159571  20000</code></pre>
</div>
<p>Assim, é criada uma matriz com 159571 linhas (número de comentários) e 20000 colunas (número de variáveis). Essa seria a matriz de <em>features</em> que utilizaríamos no nosso modelo.</p>
<p>A técnica de bag-of-words permanece com o problema de simplesmente analisar a frequência de cada palavra em um comentário. Todavia, é preciso considerar que, se uma palavra aparece comumente em muitos comentários, ela não pode agregar muito valor ao modelo. Para atenuar esse problema, usualmente é utilizada uma técnica chamada TF-IDF (<em>term frequency-inverse document frequency</em>). Neste método, a frequência de um termo calculada no bag-of-words é multiplicada por um termo denominado idf (<em>inverse document frequency</em>). O idf é calculado da seguinte forma:</p>
<p><span class="math display">\[ IDF(t, d) = \log \frac{N_d}{1 + df(d,t)} \]</span></p>
<p><span class="math inline">\(N_d\)</span> é o número de documento e <span class="math inline">\(df(d,t)\)</span> é número de documentos em que o termo <span class="math inline">\(t\)</span> aparece. Assim, o valor da variável será calculando multiplicando o número de vezes que a palavra <span class="math inline">\(w\)</span> apareceu do documento <span class="math inline">\(d\)</span> pela quantidade <span class="math inline">\(IDF(t,d)\)</span>.</p>
<p>Para calcular a matriz de features utilizando o TF-IDF, é criado um novo objeto e são utilizados os dados de treinamento para calcular os valores necessários e transformar os nossos dados. Mais a frente, iremos aplicar apenas a transformação aos dados de teste.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
tfidf &lt;- TfIdf$new(
  norm = &#39;l2&#39;
)

train_dtm_tfidf = fit_transform(train_dtm, tfidf)</code></pre>
</div>
<h2 id="bag-of-characters">Bag-of-Characters</h2>
<p>Repetimos o mesmo processo para criar uma <em>bag-of-characters</em>. No entanto, vamos usar n-grams que são combinações de n caracters. Utilizamos combinações de 2 a 6 caracteres e limitamos nosso vocabulário em 20.000 termos.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
it_train_char &lt;- itoken(
  train$comment_text,
  preprocessor = limpa_texto,
  tokenizer = char_tokenizer,
  id = train$id,
  progressbar = FALSE
)

vocabulario_char &lt;- create_vocabulary(it_train_char,
                                      ngram = c(2, 6))

vocabulario_char &lt;- prune_vocabulary(
  vocabulary = vocabulario_char,
  term_count_min = 5,
  doc_proportion_max = 0.9,
  vocab_term_max = 20000
)

toxic_vectorizer_char &lt;- vocab_vectorizer(vocabulary = vocabulario_char)

tfidf_char &lt;- TfIdf$new(
  norm = &#39;l2&#39;
)

train_dtm_char &lt;- create_dtm(
  it = it_train_char,
  vectorizer = toxic_vectorizer_char,
  type = &#39;dgCMatrix&#39;
) %&gt;% 
  fit_transform(tfidf_char)

train_dtm_tfidf &lt;- Matrix::cBind(train_dtm_tfidf, train_dtm_char)</code></pre>
</div>
<h2 id="treinando-um-classificador">Treinando um Classificador</h2>
<p>Aqui, iremos treinar um classificador para cada categoria. Será utilizado o modelo <em>elastic-net</em> que está disponível no pacote <code>glmnet</code>. Basicamente, utilizaremos uma regressão logística com uma regularização que combina penalidades do tipo <span class="math inline">\(l_1\)</span> e <span class="math inline">\(l_2\)</span>. Os parâmetros são obtidos resolvendo o seguinte problema:</p>
<p><span class="math display">\[\min_{\beta_0, \beta} \frac{1}{N}\sum_{i=1}^N w_i l(y_i, \beta_0 + \beta^Tx_i) + \lambda[(1-\alpha)||\beta||^2_2 + \alpha||\beta||_1],\]</span> em que <span class="math inline">\(N\)</span> é o número de observações, <span class="math inline">\(w_i\)</span>, <span class="math inline">\(y_i\)</span> e <span class="math inline">\(x_i\)</span> são, respectivamente, o peso, o target e o vetor de features da i-ésima observação. A função <span class="math inline">\(l(.)\)</span> é o negativo do log-likelihood, que depende da distribuição assumida. <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta^T\)</span> são parâmetros que serão estimados. Adicionalmente, <span class="math inline">\(\lambda\)</span> e <span class="math inline">\(\alpha\)</span> são hiperparâmetros que não são obtidos diretamente pela solução do problema. O parâmetro <span class="math inline">\(\lambda\)</span> controla o nível de regularização e o parâmetro <span class="math inline">\(\alpha\)</span> controla a combinação entre os dois tipos de regularização. O parâmetro <span class="math inline">\(\lambda\)</span> será obtido via validação cruzada (5 folds) e o será fixado em 0.5.</p>
<p>A função abaixo faz o cross-validation e retorna um data.frame com algumas informações, além do modelo treinado.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
classificador_toxico &lt;- function(categoria, alpha, nfolds = 5){
  
  print(categoria)
  set.seed(303022)
  folds &lt;- train %&gt;% 
    group_by(!!categoria) %&gt;% 
    mutate(fold = sample(1:nfolds, n(), replace = T)) %&gt;% 
    pull(fold)
  
  # Cálculo do peso de cada observação
  # observações como y = 1 entrarão com um peso maior
  data_weights &lt;- ifelse(train[[categoria]] == &quot;1&quot;,
                         (1/table(train[[categoria]])[2]) * 0.5,
                         (1/table(train[[categoria]])[1]) * 0.5)
  
  fit &lt;- cv.glmnet(
    x = train_dtm_tfidf,
    y = train[[categoria]],
    family = &quot;binomial&quot;,
    alpha = alpha,
    weights = data_weights,
    type.measure = &quot;auc&quot;,
    foldid = folds ,
    maxit = 1000
  )
  
  resultado &lt;- tibble(
    categoria = categoria,
    alpha = alpha,
    lambda = fit$lambda.min,
    auc = max(fit$cvm)
  )
  
  list(
    resultado = resultado,
    modelo = fit
  )
}</code></pre>
</div>
<p>Utilizaremos o pacote <code>purrr</code> para criar um classificador para cada categoria e coletar o modelo treinado e os resultados da validação.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
cv_grid &lt;- expand.grid(
  categoria = c(&quot;toxic&quot;, &quot;severe_toxic&quot;, &quot;obscene&quot;,
                &quot;threat&quot;, &quot;insult&quot;, &quot;identity_hate&quot;),
  alpha = 0.5,
  stringsAsFactors = FALSE
)

resultados_cv &lt;- pmap(
  cv_grid,
  classificador_toxico
)</code></pre>
<pre><code>
[1] &quot;toxic&quot;
[1] &quot;severe_toxic&quot;
[1] &quot;obscene&quot;
[1] &quot;threat&quot;
[1] &quot;insult&quot;
[1] &quot;identity_hate&quot;</code></pre>
<pre class="r"><code>
modelos &lt;- map(resultados_cv, &quot;modelo&quot;)
resultados &lt;- map_df(resultados_cv, &quot;resultado&quot;) %&gt;% 
  mutate(modelo = modelos) %&gt;% 
  group_by(categoria) %&gt;% 
  filter(auc == max(auc))</code></pre>
</div>
<p>Aqui, vemos quais foram os melhores valores encontrados de <span class="math inline">\(\lambda\)</span> em termos de AUC (<em>area under the curve</em>) que foi a métrica escolhida na competição.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
resultados %&gt;% 
  select(-modelo) %&gt;% 
  group_by(categoria) %&gt;% 
  filter(auc == max(auc)) %&gt;% 
  knitr::kable()</code></pre>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">categoria</th>
<th style="text-align: right;">alpha</th>
<th style="text-align: right;">lambda</th>
<th style="text-align: right;">auc</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">toxic</td>
<td style="text-align: right;">0.5</td>
<td style="text-align: right;">0.0033502</td>
<td style="text-align: right;">0.9766353</td>
</tr>
<tr class="even">
<td style="text-align: left;">severe_toxic</td>
<td style="text-align: right;">0.5</td>
<td style="text-align: right;">0.0071474</td>
<td style="text-align: right;">0.9868013</td>
</tr>
<tr class="odd">
<td style="text-align: left;">obscene</td>
<td style="text-align: right;">0.5</td>
<td style="text-align: right;">0.0046081</td>
<td style="text-align: right;">0.9897352</td>
</tr>
<tr class="even">
<td style="text-align: left;">threat</td>
<td style="text-align: right;">0.5</td>
<td style="text-align: right;">0.0049738</td>
<td style="text-align: right;">0.9863266</td>
</tr>
<tr class="odd">
<td style="text-align: left;">insult</td>
<td style="text-align: right;">0.5</td>
<td style="text-align: right;">0.0044995</td>
<td style="text-align: right;">0.9803934</td>
</tr>
<tr class="even">
<td style="text-align: left;">identity_hate</td>
<td style="text-align: right;">0.5</td>
<td style="text-align: right;">0.0076102</td>
<td style="text-align: right;">0.9776454</td>
</tr>
</tbody>
</table>
</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<p>O AUC médio foi de 0.9829229.</p>
<h2 id="predicoes-para-os-dados-de-teste">Predições para os dados de teste</h2>
<p>Por fim, vamos avaliar os modelos treinados na base de teste. Para cada comentário, são realizadas seis predições, uma para cada categoria. O score final será a média do AUC entre todas as categorias.</p>
<p>Aqui, vamos preparar os dados. Os comentários da base de teste serão vetorizados com base no vocabulário da base de treinamento.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
test &lt;- read_csv(&#39;dados/test.csv&#39;)

it_test &lt;- itoken(
  test$comment_text,
  preprocessor = limpa_texto,
  tokenizer = word_tokenizer,
  id = test$id,
  progressbar = FALSE
)

it_test_char &lt;- itoken(
  test$comment_text,
  preprocessor = limpa_texto,
  tokenizer = char_tokenizer,
  id = test$id,
  progressbar = FALSE
)

test_dtm_tfidf &lt;- create_dtm(it_test, toxic_vectorizer) %&gt;% 
  transform(tfidf) %&gt;% 
  cbind(.,
        create_dtm(it_test_char, toxic_vectorizer_char) %&gt;% 
  transform(tfidf_char))</code></pre>
</div>
<p>Abaixo, vemos os dados dos targets na base de teste.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
test_labels &lt;- read_csv(&#39;dados/test_labels.csv&#39;)
head(test_labels)</code></pre>
<pre><code>
# A tibble: 6 x 7
  id           toxic severe_toxic obscene threat insult identity_hate
  &lt;chr&gt;        &lt;int&gt;        &lt;int&gt;   &lt;int&gt;  &lt;int&gt;  &lt;int&gt;         &lt;int&gt;
1 00001cee341~    -1           -1      -1     -1     -1            -1
2 00002478678~    -1           -1      -1     -1     -1            -1
3 00013b17ad2~    -1           -1      -1     -1     -1            -1
4 00017563c3f~    -1           -1      -1     -1     -1            -1
5 00017695ad8~    -1           -1      -1     -1     -1            -1
6 0001ea8717f~     0            0       0      0      0             0</code></pre>
</div>
<p>Os valores <code>-1</code> indicam que aqueles comentários não foram utilizados no cálculo do score final. Dessa forma, teremos que desconsiderá-los na avaliação do modelo.</p>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
auc &lt;- c()
for(i in resultados$categoria){
  # recupera o modelo para a categoria i
  modelo &lt;- resultados %&gt;% 
    filter(categoria == i) %&gt;% 
    pull(modelo)
  
  modelo &lt;- modelo[[1]]$glmnet.fit
  
  # Valor do parâmetro lambda
  lambda &lt;- resultados %&gt;% 
    filter(categoria == i) %&gt;% 
    pull(lambda)
  
  # Cria indicador se a observação entra ou não no cálculo do score
  valido &lt;- test_labels[[i]] != -1
  
  # Predições
  pred &lt;- predict(modelo, test_dtm_tfidf, s = lambda, type = &quot;response&quot;)[,1]
  
  # Valores observados
  y &lt;- test_labels[[i]]
  
  # Cálculo do AUC
  auc &lt;- c(auc, MLmetrics::AUC(pred[valido], y[valido]))
  
}

names(auc) &lt;- resultados$categoria
auc</code></pre>
<pre><code>
        toxic  severe_toxic       obscene        threat        insult 
    0.9618778     0.9833989     0.9757907     0.9878752     0.9701873 
identity_hate 
    0.9813508 </code></pre>
</div>
<p>O AUC médio na base de teste é igual a 0.9767. Este é o nosso resultado! Na plataforma do Kaggle, obtemos os seguintes resultados (ligeiramente diferentes):</p>
<p><img src="imagens/score_kaggle.png" /></p>
<p>Obviamente, esse resultado não faz cócegas nos resultados obtidos pelos primeiros lugares. No entanto, considerando a classe de modelos lineares, nossos resultados são razoáveis. Inclusive, comparáveis aos resultados dos principais kernel para algoritmos que não está na categoria <em>deep learning</em>.</p>
<h2 id="proximos-passos">Próximos Passos</h2>
<p>A ideia é apresentar no futuro, para esse mesmo conjunto de dados, resultados utilizando técnicas de deep learning, mas por hoje é só! Espero que o post tenha trazido algo de útil.</p>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom"></div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
