---
title: "Scraping de dados da CBF com rvest"
description: |
  Nesse post apresentaremos um tutorial básico de web scraping utilizando o pacote rvest e o as informações de jogos divulgadas no site da CBF. Rvest é um pacote que simplifica muito tarefas de scraping e vai te ajudar a transformar qualquer site em dados no R.
date: 07-16-2019
author:
  - name: Miguel Cleaver
    url: https://github.com/mgcleaver
output:
  distill::distill_article:
    self_contained: false
categories:
  - rvest
  - scraping
preview: ../../images/cbf.gif
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
<!-- More -->

## O que é web scraping?

É uma técnica de extração de dados de websites de forma automatizada. A web hoje traz inúmeras informações e dados que não estão disponíveis para serem baixados em arquivos  estruturados como os arquivos xlsx (excel) ou csv. Como exemplo, podemos ver a página em do [Wikipédia sobre o Brasil](https://pt.wikipedia.org/wiki/Brasil). Há uma série de informações e dados no site que não estão organizados nem disponíveis para download. 

Abaixo podemos ver que o site apresenta dados de PIB (PPC), PIB (nominal), IDH, Índice de Gini, moeda, fuso horário, entre outros dados brasileiros:

```{r, echo = F, fig.align='center'}
knitr::include_graphics('../../images/web_scraping.png')
```

À primeira vista a extração de dados da web pode parecer mais fácil se feita manualmente, bastando um simples copia e cola. Isso funciona bem quando há poucos dados a serem extraídos. No entanto, à medida que a quantidade de dados para extração aumenta, a tarefa se torna tediosa, sujeita a erros e demorada. 

Imagine ter que extrair do Wikipédia a informação dos presidentes atuais de uma lista de 100 países. Você teria que entrar na respectiva seção do Wikipédia de cada país e extrair essa informação. É algo que não faz sentido se você tem noções de web scraping. Como algumas linhas de código você conseguiria extrair as informações desejadas.

## Como fazemos web scraping com R?

Fazer web scraping com R é bastante intuitivo graças ao pacote [rvest](https://www.rdocumentation.org/packages/rvest/versions/0.3.4). O ideal é conhecer um pouco de HTML para se familiarizar com a estrutura do dado, mas não é requisito necessário ter conhecimentos avançados sobre o assunto como veremos no exemplo a seguir.

## Exemplo: raspando dados disponíveis no portal da CBF

Para mostrar como fazer web scraping, escolhemos um caso relativamente simples: vamos extrair dados do portal da [CBF](https://www.cbf.com.br/), o qual traz informações sobre as colocações dos times e resultados dos jogos do Brasileirão.

O objetivo é extrair as informações da coluna interativa lateral direita que apresenta os resultados de cada rodada, conforme pode ser visto abaixo:

```{r, echo = F, fig.align='center'}
knitr::include_graphics('../../images/cbf.gif')
```

Até o momento da publicação deste post, apenas 10 rodadas do Brasileirão haviam sido realizadas. Contudo, veremos que com o código que será construído não precisaremos fazer esforço adicional para obter as atualizações dos resultados, uma vez que o mapeamento da estrutura de dados atual também permite mapear a atualização das rodadas futuras (estamos partindo do pressuposto que estrutura de HTML do portal da CBF não vai se alterar, pelo menos no curto prazo).

O primeiro passo consiste em carregar os pacotes necessários e puxar as informações HTML do portal da CBF. A função `read_html` se encarrega de trazer os dados HTML. O único que precisamos fazer é passar o link do site na função.


```{r, warning=FALSE, message=FALSE}

library(rvest) # pacote para web scraping
library(tidyverse)

dado_cbf <- read_html("https://www.cbf.com.br")

dado_cbf
```

Para quem não está familiarizado com o formato HTML as informações do objeto `dado_cbf` podem ser um obstáculo, mas não o são. Na verdade, o que você precisa entender é que qualquer página web é basicamente um texto com formato HTML. As informações estão contidas em tags, que por sua vez podem ter classes. Exemplos de tags são \<head\>, \<body\>, \<div\>, etc. Por sua vez, as classes estão ligadas a uma ou mais tags. Por exemplo, em \<div class="swipe bordas"\>, temos a tag `div`, mas também temos duas classes: `swipe` e `bordas`. Cuidado para não achar que se trata de uma classe única chamada `swipe bordas`. Em HTML, o espaço separa as classes, portanto, há duas classes e não uma. Com isso em mente, podemos avançar.

Para iniciarmos a extração de dados, precisamos abrir o portal da CBF e localizar os dados que desejamos "raspar". Neste caso, estamos usando o google chrome, mas qualquer navegador moderno poderá servir. Depois de localizarmos os dados, clicamos em cima do dado desejado com o botão direito do mouse e selecionamos inspecionar. Na figura abaixo, clicamos em cima do placar para inspecionar as tags e classes HTML. Observa-se que o placar tem a tag `span` e possui as classes `bg-blue`, `color-white` e `label-2`. 

```{r, echo=FALSE}
knitr::include_graphics('../../images/html_scraping.gif')
```

Além disso vamos perceber que entre a abertura e o fechamento da tag span temos um texto, que é justamente o placar que foi clicado com o botão direito do mouse. Se você clicar em diferentes placares , vai notar que as tags junto com as classes se repetem. Estamos observando que há um padrão nos dados HTML. É esse padrão que nos permite extrair dados de maneira automatizada. 

Inspecionar dados HTML pode demorar um pouco até você pegar o jeito, mas uma vez que você entende a estrutura fica fácil buscar o dado pela tag e pela classe que você deseja. Eu já localizei para vocês que a principal classe que estamos interessados é a swiper-slide. Essa classe engloba a coluna inteira de rodadas. 

Agora utilizamos a função `html_nodes`.  No argumento da função pode-se passar uma classe ou uma tag, por exemplo. Para classes, devemos usar um "." antes da classe desejada. Mas, para tags, basta inserir o nome da tag direto na função. 


```{r,}

dado_cbf <- dado_cbf %>% 
  html_nodes(".swiper-slide")

print(dado_cbf)
```

Agora estamos vendo que `dado_cbf` possui uma sequência de linhas com várias tags do tipo `div` com classe `swiper-slide`. Cada uma dessas tags possui uma coluna com resultados. Assim, explorando cada `div`, podemos extrair as informações desejadas. Por exemplo, ao explorar o HTML, já descobri que a tag com classe `swiper-slide` engloba a tag com classe `aside-header` que engloba a tag com classe `text-center` que nos leva a uma informação do número da rodada. Vejamos:


```{r}
rodada <- dado_cbf %>% 
  html_nodes(".aside-header .text-center") %>% 
  html_text()

print(rodada)
```

Também identifiquei que a tag da classe `aside-content` engloba a tag da classe `clearfix`, as quais capturam informações de cada um dos jogos por rodada. Por sua vez, a partir das informações capturadas para cada jogo, observa-se que a tag da classe `pull-left` engloba a tag da classe `time-sigla`, a qual traz informações textuais da sigla do time da casa. Para extrair a sigla do time que joga fora de casa, uma lógica semelhante pode ser usada. Por fim, também extraímos os placares identificando a classe correspondente `partida-horario`. Ao encontrar as tags que possuem as informações desejadas, basta usar a função `html_text` para fazer a extração.

```{r}

resultados <- dado_cbf %>% 
  html_nodes(".aside-content .clearfix")

casa <- resultados %>% 
  html_nodes(".pull-left .time-sigla") %>% 
  html_text()

fora_casa <- resultados %>% 
  html_nodes(".pull-right .time-sigla") %>% 
  html_text()

placar <- resultados %>% 
  html_nodes(".partida-horario") %>% 
  html_text() %>% 
  str_extract("[0-9]{1}\ x\ [0-9]{1}")
```

Com algumas linhas de código extraímos informações do site da CBF de forma simples e rápida. O scrapping é basicamente isso. Depois de "raspar" os dados, podemos, finalmente, estrutura os dados. Vejamos:

```{r}
rodada <- 0:(length(placar)-1) %/% 10 + 1

df <- data.frame(rodada = rodada,
           casa = casa, 
           fora_casa = fora_casa,
           placar = placar,
           stringsAsFactors = FALSE) %>% 
  filter(rodada <= 10)

rmarkdown::paged_table(df)
```



